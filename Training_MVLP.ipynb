{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library and APIs\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mp1\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import array as arr\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import timeit\n",
    "\n",
    "from pandas import DataFrame\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    def __init__(self, id, filename, img, gender, age, angle):\n",
    "        self.id = id\n",
    "        self.filename = filename\n",
    "        self.img = img\n",
    "        self.gender = gender\n",
    "        self.age = age\n",
    "        self.angle = angle\n",
    "        self.guessGender = 0\n",
    "        self.guessAge = 0\n",
    "        self.guessAngle = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .csv file and store in df\n",
    "# Read the .txt file to get the training id list\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('subject_info_OUMVLP.csv')\n",
    "id_train = np.loadtxt(\"IDList_train_OUMVLP.txt\", dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = r\"C:/Users/Martin/FYP/GEI_OUMVLP/\"\n",
    "files = os.listdir(datadir)\n",
    "\n",
    "all_people = []\n",
    "height = 0 \n",
    "width = 0\n",
    "\n",
    "df.ID = df.ID.astype(str)\n",
    "for index, data in df.iterrows():\n",
    "    id = (5-len(data.ID))*'0' + data.ID\n",
    "    gender = 1 if data.gender == 'M' else 0\n",
    "    age = data.age\n",
    "    if age == '-':\n",
    "        age = '-'\n",
    "    else:\n",
    "        age = int(age)\n",
    "    \n",
    "    temp_id_list = []\n",
    "    for file in files:\n",
    "        angle = int(file.split('-')[0])\n",
    "        sequence = int(file.split('-')[1])\n",
    "        \n",
    "        if sequence == 1:\n",
    "            if id in temp_id_list :\n",
    "                temp_id_list = []\n",
    "                continue\n",
    "            temp_id_list = []\n",
    "        \n",
    "        filename = datadir + file + '/' + id + '.png'\n",
    "        img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "        if type(img) == type(None):\n",
    "            continue\n",
    "        \n",
    "        p = Person(id, filename, img, gender, age, angle)\n",
    "        all_people.append(p)\n",
    "        temp_id_list.append(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = [0, 15, 30, 45, 60, 75, 90, 180, 195, 210, 225, 240, 255, 270]\n",
    "\n",
    "all_people_with_angle = {}\n",
    "\n",
    "for p in all_people:\n",
    "    if p.angle not in all_people_with_angle:\n",
    "        all_people_with_angle[p.angle] = []\n",
    "    all_people_with_angle[p.angle].append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_train = []\n",
    "people_test = []\n",
    "\n",
    "for p in all_people:\n",
    "    if int(p.id) in id_train:\n",
    "        people_train.append(p)\n",
    "    else:\n",
    "        people_test.append(p)\n",
    "        \n",
    "height, width = all_people[0].img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model layers without output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(18, (7, 7), strides = 1, activation = 'relu', input_shape = (height, width, 1)))\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(45, (5, 5), strides = 1, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (3,3), strides = 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "\n",
    "model.save(\"model_MVLP/MVLP_without_output_layer.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                14350     \n",
      "=================================================================\n",
      "Total params: 23,261,141\n",
      "Trainable params: 23,261,015\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block_angle = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "block_angle.add(Dense(14, activation = 'softmax'))\n",
    "block_angle.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "block_angle.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cat(arr):\n",
    "    y = []\n",
    "    \n",
    "    for angle in arr:\n",
    "        temp = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        index = category.index(angle)\n",
    "        \n",
    "        temp[index] = 1\n",
    "        y.append(temp)\n",
    "    \n",
    "    return np.array(y, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68799, 14)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in people_train:\n",
    "    x_train.append(p.img)\n",
    "    y_train.append(p.angle)\n",
    "    \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = np.array(y_train, dtype='int32')\n",
    "\n",
    "y_train = to_cat(y_train)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69015, 14)\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in people_test:\n",
    "    x_test.append(p.img)\n",
    "    y_test.append(p.angle)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = np.array(y_test, dtype='int32')\n",
    "\n",
    "y_test = to_cat(y_test)\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    history = model.fit(x_train, y_train, epochs = 5)\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose = 1)\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2150/2150 [==============================] - 17s 6ms/step - loss: 0.2854 - accuracy: 0.9439\n",
      "Epoch 2/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0768 - accuracy: 0.9770\n",
      "Epoch 3/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0569 - accuracy: 0.9833\n",
      "Epoch 4/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0428 - accuracy: 0.9874\n",
      "Epoch 5/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0376 - accuracy: 0.9892\n",
      "2157/2157 [==============================] - 5s 2ms/step - loss: 0.0758 - accuracy: 0.9774\n",
      "Epoch 1/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0296 - accuracy: 0.9911\n",
      "Epoch 2/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0257 - accuracy: 0.9928 0s -\n",
      "Epoch 3/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0162 - accuracy: 0.9951\n",
      "Epoch 4/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0158 - accuracy: 0.9953\n",
      "Epoch 5/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0130 - accuracy: 0.9959\n",
      "2157/2157 [==============================] - 5s 2ms/step - loss: 0.0601 - accuracy: 0.9893\n",
      "Epoch 1/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0129 - accuracy: 0.9961\n",
      "Epoch 2/5\n",
      "2150/2150 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9970 ETA: 1s - los - ETA: 0s - l - 13s 6ms/step - loss: 0.0106 - accuracy: 0.9970\n",
      "Epoch 3/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0098 - accuracy: 0.9973\n",
      "Epoch 4/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0086 - accuracy: 0.9976\n",
      "Epoch 5/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0083 - accuracy: 0.9975\n",
      "2157/2157 [==============================] - 5s 2ms/step - loss: 0.0668 - accuracy: 0.9880\n",
      "Epoch 1/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0070 - accuracy: 0.9979\n",
      "Epoch 2/5\n",
      "2150/2150 [==============================] - 13s 6ms/step - loss: 0.0090 - accuracy: 0.9975 0s - loss: 0.0090 - accuracy: 0. - ETA: 0s - loss: 0.0091 - accura\n",
      "Epoch 3/5\n",
      " 729/2150 [=========>....................] - ETA: 8s - loss: 0.0066 - accuracy: 0.9984"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-87cfd3da7253>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mnew_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock_angle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_acc\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-80350a489cb1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \"\"\"\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    513\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \"\"\"\n\u001b[0;32m   1093\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1094\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1095\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1058\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc = 0.9911\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(True):\n",
    "        epochs += 50\n",
    "        new_acc = train(block_angle)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            #block_angle.save(\"model_MVLP/MVLP_angle.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "            print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2157/2157 [==============================] - 18s 7ms/step - loss: 0.1091 - accuracy: 0.9911\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"GPU:0\"):\n",
    "    block_angle = tf.keras.models.load_model(\"model_MVLP/MVLP_angle.h5\")\n",
    "    test_loss, test_acc = block_angle.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 10307 Angle: 270 Guess: 270\r"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "with tf.device(\"GPU:0\"):\n",
    "    for p in all_people:\n",
    "        img = np.array(p.img).reshape(-1, height, width, 1)\n",
    "        predict_angle = block_angle.predict(img)\n",
    "        p.guessAngle = category[np.argmax(predict_angle)]\n",
    "\n",
    "        b = \"ID: \"+ p.id + \" Angle: \" + str(p.angle) + \" Guess: \" + str(p.guessAngle)\n",
    "        print (b, end=\"\\r\")\n",
    "stop = timeit.default_timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Prediction Time: ', round((stop - start)/60), 'minutes\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_angle_0_180 = []\n",
    "train_angle_15_195 = []\n",
    "train_angle_30_45 = []\n",
    "train_angle_60_75_90 = []\n",
    "train_angle_210_225 = []\n",
    "train_angle_240_255_270 = []\n",
    "\n",
    "test_angle_0_180 = []\n",
    "test_angle_15_195 = []\n",
    "test_angle_30_45 = []\n",
    "test_angle_60_75_90 = []\n",
    "test_angle_210_225 = []\n",
    "test_angle_240_255_270 = []\n",
    "\n",
    "for p in people_train:\n",
    "    if p.guessAngle == 0 or p.guessAngle == 180:\n",
    "        train_angle_0_180.append(p)\n",
    "        \n",
    "    elif p.guessAngle == 15 or p.guessAngle == 195:\n",
    "        train_angle_15_195.append(p)\n",
    "    \n",
    "    elif p.guessAngle == 30 or p.guessAngle == 45:\n",
    "        train_angle_30_45.append(p)\n",
    "        \n",
    "    elif p.guessAngle == 60 or p.guessAngle == 75 or p.guessAngle == 90:\n",
    "        train_angle_60_75_90.append(p)\n",
    "        \n",
    "    elif p.guessAngle == 210 or p.guessAngle == 225:\n",
    "        train_angle_210_225.append(p)\n",
    "    else:\n",
    "        train_angle_240_255_270.append(p)\n",
    "        \n",
    "for p in people_test:\n",
    "    if p.guessAngle == 0 or p.guessAngle == 180:\n",
    "        test_angle_0_180.append(p)\n",
    "        \n",
    "    elif p.guessAngle == 15 or p.guessAngle == 195:\n",
    "        test_angle_15_195.append(p)\n",
    "    \n",
    "    elif p.guessAngle == 30 or p.guessAngle == 45:\n",
    "        test_angle_30_45.append(p)\n",
    "        \n",
    "    elif p.guessAngle == 60 or p.guessAngle == 75 or p.guessAngle == 90:\n",
    "        test_angle_60_75_90.append(p)\n",
    "        \n",
    "    elif p.guessAngle == 210 or p.guessAngle == 225:\n",
    "        test_angle_210_225.append(p)\n",
    "    else:\n",
    "        test_angle_240_255_270.append(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gnder with angle 0 and 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,248,841\n",
      "Trainable params: 23,248,715\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block_gender_0_180 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "block_gender_0_180.add(Dense(2, activation = 'softmax'))\n",
    "block_gender_0_180.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "block_gender_0_180.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9417, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_angle_0_180:\n",
    "    x_train.append(p.img)\n",
    "    y_train.append(p.gender)\n",
    "    \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = np.array(y_train, dtype='int32')\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9416, 2)\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_angle_0_180:\n",
    "    x_test.append(p.img)\n",
    "    y_test.append(p.gender)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = np.array(y_test, dtype='int32')\n",
    "\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(acc < 0.94):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_gender_0_180)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_gender_0_180.save(\"model_MVLP/MVLP_gender_0_180.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "            print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 2s 7ms/step - loss: 0.7292 - accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "block_gender_0_180 = tf.keras.models.load_model(\"model_MVLP/MVLP_gender_0_180.h5\")\n",
    "test_loss, test_acc = block_gender_0_180.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 10305 Guess: 0\r"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    for p in all_people:\n",
    "        if p.guessAngle != 0 and p.guessAngle != 180:\n",
    "            continue\n",
    "        img = np.array(p.img).reshape(-1, height, width, 1)\n",
    "        predict_gender = block_gender_0_180.predict(img)\n",
    "        p.guessGender = np.argmax(predict_gender)\n",
    "\n",
    "        b = \"ID: \"+ p.id + \" Guess: \" + str(p.guessGender)\n",
    "        print (b, end=\"\\r\")\n",
    "\n",
    "stop = timeit.default_timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gnder with angle 15 and 195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,248,841\n",
      "Trainable params: 23,248,715\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block_gender_15_195 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "block_gender_15_195.add(Dense(2, activation = 'softmax'))\n",
    "block_gender_15_195.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "block_gender_15_195.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9686, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_angle_15_195:\n",
    "    x_train.append(p.img)\n",
    "    y_train.append(p.gender)\n",
    "    \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = np.array(y_train, dtype='int32')\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9698, 2)\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_angle_15_195:\n",
    "    x_test.append(p.img)\n",
    "    y_test.append(p.gender)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = np.array(y_test, dtype='int32')\n",
    "\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(True):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_gender_15_195)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_gender_15_195.save(\"model_MVLP/MVLP_gender_15_195.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "            print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304/304 [==============================] - 2s 7ms/step - loss: 0.8433 - accuracy: 0.9413\n"
     ]
    }
   ],
   "source": [
    "block_gender_15_195 = tf.keras.models.load_model(\"model_MVLP/MVLP_gender_15_195.h5\")\n",
    "test_loss, test_acc = block_gender_15_195.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 10307 Guess: 1\r"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    for p in all_people:\n",
    "        if p.guessAngle != 15 and p.guessAngle != 195:\n",
    "            continue\n",
    "        img = np.array(p.img).reshape(-1, height, width, 1)\n",
    "        predict_gender = block_gender_15_195.predict(img)\n",
    "        p.guessGender = np.argmax(predict_gender)\n",
    "\n",
    "        b = \"ID: \"+ p.id + \" Guess: \" + str(p.guessGender)\n",
    "        print (b, end=\"\\r\")\n",
    "\n",
    "stop = timeit.default_timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gnder with angle 30 and 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,248,841\n",
      "Trainable params: 23,248,715\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block_gender_30_45 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "block_gender_30_45.add(Dense(2, activation = 'softmax'))\n",
    "block_gender_30_45.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "block_gender_30_45.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10026, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_angle_30_45:\n",
    "    x_train.append(p.img)\n",
    "    y_train.append(p.gender)\n",
    "    \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = np.array(y_train, dtype='int32')\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10051, 2)\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_angle_30_45:\n",
    "    x_test.append(p.img)\n",
    "    y_test.append(p.gender)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = np.array(y_test, dtype='int32')\n",
    "\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(True):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_gender_30_45)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_gender_30_45.save(\"model_MVLP/MVLP_gender_30_45.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "            print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 2s 7ms/step - loss: 0.5097 - accuracy: 0.9594\n"
     ]
    }
   ],
   "source": [
    "block_gender_30_45 = tf.keras.models.load_model(\"model_MVLP/MVLP_gender_30_45.h5\")\n",
    "test_loss, test_acc = block_gender_30_45.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 10306 Guess: 1\r"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    for p in all_people:\n",
    "        if p.guessAngle != 30 and p.guessAngle != 45:\n",
    "            continue\n",
    "        img = np.array(p.img).reshape(-1, height, width, 1)\n",
    "        predict_gender = block_gender_30_45.predict(img)\n",
    "        p.guessGender = np.argmax(predict_gender)\n",
    "\n",
    "        b = \"ID: \"+ p.id + \" Guess: \" + str(p.guessGender)\n",
    "        print (b, end=\"\\r\")\n",
    "\n",
    "stop = timeit.default_timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gnder with angle 60, 75 and 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,248,841\n",
      "Trainable params: 23,248,715\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block_gender_60_75_90 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "block_gender_60_75_90.add(Dense(2, activation = 'softmax'))\n",
    "block_gender_60_75_90.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "block_gender_60_75_90.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14816, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_angle_60_75_90:\n",
    "    x_train.append(p.img)\n",
    "    y_train.append(p.gender)\n",
    "    \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = np.array(y_train, dtype='int32')\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14876, 2)\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_angle_60_75_90:\n",
    "    x_test.append(p.img)\n",
    "    y_test.append(p.gender)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = np.array(y_test, dtype='int32')\n",
    "\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(True):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_gender_60_75_90)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_gender_60_75_90.save(\"model_MVLP/MVLP_gender_60_75_90.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "            print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465/465 [==============================] - 3s 7ms/step - loss: 0.4984 - accuracy: 0.9584\n"
     ]
    }
   ],
   "source": [
    "block_gender_60_75_90 = tf.keras.models.load_model(\"model_MVLP/MVLP_gender_60_75_90.h5\")\n",
    "test_loss, test_acc = block_gender_60_75_90.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 10306 Guess: 0\r"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    for p in all_people:\n",
    "        if p.guessAngle != 60 and p.guessAngle != 75 and p.guessAngle != 90:\n",
    "            continue\n",
    "        img = np.array(p.img).reshape(-1, height, width, 1)\n",
    "        predict_gender = block_gender_60_75_90.predict(img)\n",
    "        p.guessGender = np.argmax(predict_gender)\n",
    "\n",
    "        b = \"ID: \"+ p.id + \" Guess: \" + str(p.guessGender)\n",
    "        print (b, end=\"\\r\")\n",
    "\n",
    "stop = timeit.default_timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gnder with angle 210 and 225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,248,841\n",
      "Trainable params: 23,248,715\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block_gender_210_225 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "block_gender_210_225.add(Dense(2, activation = 'softmax'))\n",
    "block_gender_210_225.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "block_gender_210_225.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10075, 2)\n",
      "(10098, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_angle_210_225:\n",
    "    x_train.append(p.img)\n",
    "    y_train.append(p.gender)\n",
    "    \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = np.array(y_train, dtype='int32')\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_angle_210_225:\n",
    "    x_test.append(p.img)\n",
    "    y_test.append(p.gender)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = np.array(y_test, dtype='int32')\n",
    "\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(True):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_gender_210_225)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_gender_210_225.save(\"model_MVLP/MVLP_gender_210_225.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "            print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316/316 [==============================] - 2s 7ms/step - loss: 0.3143 - accuracy: 0.9568\n"
     ]
    }
   ],
   "source": [
    "block_gender_210_225 = tf.keras.models.load_model(\"model_MVLP/MVLP_gender_210_225.h5\")\n",
    "test_loss, test_acc = block_gender_210_225.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 10307 Guess: 1\r"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    for p in all_people:\n",
    "        if p.guessAngle != 210 and p.guessAngle != 225:\n",
    "            continue\n",
    "        img = np.array(p.img).reshape(-1, height, width, 1)\n",
    "        predict_gender = block_gender_210_225.predict(img)\n",
    "        p.guessGender = np.argmax(predict_gender)\n",
    "\n",
    "        b = \"ID: \"+ p.id + \" Guess: \" + str(p.guessGender)\n",
    "        print (b, end=\"\\r\")\n",
    "\n",
    "stop = timeit.default_timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gnder with angle 240, 255 and 270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,248,841\n",
      "Trainable params: 23,248,715\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block_gender_240_255_270 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "block_gender_240_255_270.add(Dense(2, activation = 'softmax'))\n",
    "block_gender_240_255_270.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "block_gender_240_255_270.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14779, 2)\n",
      "(14876, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_angle_240_255_270:\n",
    "    x_train.append(p.img)\n",
    "    y_train.append(p.gender)\n",
    "    \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = np.array(y_train, dtype='int32')\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_angle_240_255_270:\n",
    "    x_test.append(p.img)\n",
    "    y_test.append(p.gender)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = np.array(y_test, dtype='int32')\n",
    "\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(True):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_gender_240_255_270)\n",
    "        b = \"Epochs: \"+ str(epochs)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_gender_240_255_270.save(\"model_MVLP/MVLP_gender_240_255_270.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "        print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465/465 [==============================] - 3s 7ms/step - loss: 0.7844 - accuracy: 0.9525: 3s - loss:\n"
     ]
    }
   ],
   "source": [
    "block_gender_240_255_270 = tf.keras.models.load_model(\"model_MVLP/MVLP_gender_240_255_270.h5\")\n",
    "test_loss, test_acc = block_gender_240_255_270.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 10307 Guess: 1\r"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    for p in all_people:\n",
    "        if p.guessAngle != 240 and p.guessAngle != 255 and p.guessAngle != 270:\n",
    "            continue\n",
    "        img = np.array(p.img).reshape(-1, height, width, 1)\n",
    "        predict_gender = block_gender_240_255_270.predict(img)\n",
    "        p.guessGender = np.argmax(predict_gender)\n",
    "\n",
    "        b = \"ID: \"+ p.id + \" Guess: \" + str(p.guessGender)\n",
    "        print (b, end=\"\\r\")\n",
    "\n",
    "stop = timeit.default_timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict gender by angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_female = []\n",
    "train_male = []\n",
    "\n",
    "test_female = []\n",
    "test_male = []\n",
    "\n",
    "for p in people_train:\n",
    "    if p.guessGender == 0:\n",
    "        train_female.append(p)\n",
    "    else:\n",
    "        train_male.append(p)\n",
    "        \n",
    "for p in people_test:\n",
    "    if p.guessGender == 0:\n",
    "        test_female.append(p)\n",
    "    else:\n",
    "        test_male.append(p)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training age with Female_0_180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    history = model.fit(x_train, y_train, epochs = 5)\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose = 1)\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_cate(arr):\n",
    "    min = 2\n",
    "    max = 87\n",
    "    y = []\n",
    "    \n",
    "    for age in arr:\n",
    "        temp = [0]*(max-min+1)\n",
    "        temp[age-2]+=1\n",
    "        y.append(temp)\n",
    "    \n",
    "    return np.array(y, dtype='int32')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 26, 16, 60)        24360     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 8, 60)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 13, 8, 60)         240       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6240)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              6390784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 86)                88150     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 86)                0         \n",
      "=================================================================\n",
      "Total params: 6,529,077\n",
      "Trainable params: 6,526,783\n",
      "Non-trainable params: 2,294\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(18, (7, 7), strides = 1, activation = 'relu', input_shape = (height, width, 1)))\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(45, (5, 5), strides = 1, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (3,3), strides = 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(60, (3, 3), strides = 1, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(86, activation = 'softmax'))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.save(\"model_MVLP/MVLP_non_trained_layer3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4647, 86)\n",
      "(4679, 86)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_female:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 0 or p.guessAngle == 180:\n",
    "        x_train.append(p.img)\n",
    "        y_train.append(p.age)\n",
    "        \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = to_cate(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_female:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 0 or p.guessAngle == 180:\n",
    "        x_test.append(p.img)\n",
    "        y_test.append(p.age)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = to_cate(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    block_age_F_0_180 = tf.keras.models.load_model('model_MVLP/MVLP_non_trained_layer3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0.0885\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(epochs<1000):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_age_F_0_180)\n",
    "        b = \"Epochs: \"+ str(epochs)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_age_F_0_180.save(\"model_MVLP/MVLP_age_F_0_180.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "        print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 11s 7ms/step - loss: 3.8634 - accuracy: 0.0885 0s - los\n"
     ]
    }
   ],
   "source": [
    "block_age_F_0_180 = tf.keras.models.load_model(\"model_MVLP/MVLP_age_F_0_180.h5\")\n",
    "test_loss, test_acc = block_age_F_0_180.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training age with Male_0_180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4584, 86)\n",
      "(4532, 86)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_male:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 0 or p.guessAngle == 180:\n",
    "        x_train.append(p.img)\n",
    "        y_train.append(p.age)\n",
    "        \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = to_cate(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_male:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 0 or p.guessAngle == 180:\n",
    "        x_test.append(p.img)\n",
    "        y_test.append(p.age)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = to_cate(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    block_age_M_0_180 = tf.keras.models.load_model('model_MVLP/MVLP_non_trained_layer3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 36ms/step - loss: 10.6277 - accuracy: 0.0325\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 10.2258 - accuracy: 0.0537\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.9828 - accuracy: 0.0650\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.7602 - accuracy: 0.0702\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 9.7134 - accuracy: 0.0761\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 5.3365 - accuracy: 0.0644\n",
      "\n",
      " Epochs: 5 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.5672 - accuracy: 0.0801\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.6160 - accuracy: 0.0938\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 9.4077 - accuracy: 0.0877\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.3631 - accuracy: 0.0973\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.6137 - accuracy: 0.0953\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 3.9533 - accuracy: 0.0719\n",
      "\n",
      " Epochs: 10 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 9.5260 - accuracy: 0.1043\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.2062 - accuracy: 0.1043\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.4804 - accuracy: 0.1067\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 9.4754 - accuracy: 0.1093\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.4598 - accuracy: 0.1209\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 3.7502 - accuracy: 0.0821\n",
      "\n",
      " Epochs: 15 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 9.5610 - accuracy: 0.1191\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 9.3407 - accuracy: 0.1171\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.2281 - accuracy: 0.1235\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.2192 - accuracy: 0.1355\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 9.1764 - accuracy: 0.1409\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 3.8118 - accuracy: 0.0805\n",
      "\n",
      " Epochs: 20 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.1120 - accuracy: 0.1383\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.3008 - accuracy: 0.1368\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 9.2419 - accuracy: 0.1462\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.3393 - accuracy: 0.1451\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.2676 - accuracy: 0.1586\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 7.5706 - accuracy: 0.0368\n",
      "\n",
      " Epochs: 25 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 9.1449 - accuracy: 0.1688\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.1502 - accuracy: 0.1651\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.1569 - accuracy: 0.1736\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 9.1274 - accuracy: 0.1721\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.0965 - accuracy: 0.1795\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 5.5282 - accuracy: 0.0655\n",
      "\n",
      " Epochs: 30 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 8.9605 - accuracy: 0.1824\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 9.3128 - accuracy: 0.1907\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.1429 - accuracy: 0.1835\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.2177 - accuracy: 0.1867\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.9534 - accuracy: 0.2068\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 4.1028 - accuracy: 0.0902\n",
      "\n",
      " Epochs: 35 Acc: 0.09024713188409805 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 9.0190 - accuracy: 0.2223\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.9715 - accuracy: 0.2295\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.7914 - accuracy: 0.2456\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 8.9268 - accuracy: 0.2515\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.8134 - accuracy: 0.2561\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 4.5586 - accuracy: 0.0916\n",
      "\n",
      " Epochs: 40 Acc: 0.09157104790210724 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.9861 - accuracy: 0.2581\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 8.8033 - accuracy: 0.2733\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.6901 - accuracy: 0.2954\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.7762 - accuracy: 0.2904\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 8.7276 - accuracy: 0.3004\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 4.6187 - accuracy: 0.0916\n",
      "\n",
      " Epochs: 45 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.6244 - accuracy: 0.3115\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.6522 - accuracy: 0.3198\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.7071 - accuracy: 0.3102\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.4568 - accuracy: 0.3338\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.4455 - accuracy: 0.3495\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 4.6865 - accuracy: 0.0774\n",
      "\n",
      " Epochs: 50 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.4939 - accuracy: 0.3436\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.5128 - accuracy: 0.3486\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.6857 - accuracy: 0.2958\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.7128 - accuracy: 0.3292\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.7317 - accuracy: 0.3401\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 4.7978 - accuracy: 0.0850\n",
      "\n",
      " Epochs: 55 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.6806 - accuracy: 0.3484\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.5583 - accuracy: 0.3700\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.4215 - accuracy: 0.3794\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.5012 - accuracy: 0.3761\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.6159 - accuracy: 0.3715\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 5.1919 - accuracy: 0.0909\n",
      "\n",
      " Epochs: 60 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.3336 - accuracy: 0.3907\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.3154 - accuracy: 0.3935\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.4638 - accuracy: 0.4023\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.3945 - accuracy: 0.3986\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.3546 - accuracy: 0.4084\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 5.2077 - accuracy: 0.0770\n",
      "\n",
      " Epochs: 65 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.3875 - accuracy: 0.3957\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.3205 - accuracy: 0.4095\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 8.1953 - accuracy: 0.4160\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.4210 - accuracy: 0.4110\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.5233 - accuracy: 0.4040\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 5.5929 - accuracy: 0.0744 0s - loss: 5.5437 - accuracy: \n",
      "\n",
      " Epochs: 70 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 8.4816 - accuracy: 0.4112\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.2152 - accuracy: 0.4239\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.2407 - accuracy: 0.4293\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 8.5640 - accuracy: 0.4064\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.1277 - accuracy: 0.4298\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 15.4693 - accuracy: 0.0031\n",
      "\n",
      " Epochs: 75 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 8.3240 - accuracy: 0.4234\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 35ms/step - loss: 8.4193 - accuracy: 0.4195\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.5781 - accuracy: 0.4138\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.2159 - accuracy: 0.4335\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.2380 - accuracy: 0.4330\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 6.2090 - accuracy: 0.0794\n",
      "\n",
      " Epochs: 80 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.5659 - accuracy: 0.4173\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.2508 - accuracy: 0.4319\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.2043 - accuracy: 0.4322\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.4253 - accuracy: 0.4280\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.3217 - accuracy: 0.4254\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 6.5305 - accuracy: 0.0845\n",
      "\n",
      " Epochs: 85 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.3014 - accuracy: 0.4311\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.4563 - accuracy: 0.4099\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.2510 - accuracy: 0.4328\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.4495 - accuracy: 0.4245\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.3106 - accuracy: 0.4346\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 6.1956 - accuracy: 0.0850\n",
      "\n",
      " Epochs: 90 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.0563 - accuracy: 0.4542\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.2151 - accuracy: 0.4378\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1550 - accuracy: 0.4452\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1327 - accuracy: 0.4459\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2783 - accuracy: 0.4450\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 6.1330 - accuracy: 0.0812\n",
      "\n",
      " Epochs: 95 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.3190 - accuracy: 0.4424\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1051 - accuracy: 0.4551\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.3051 - accuracy: 0.4394\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.2051 - accuracy: 0.4505\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.1621 - accuracy: 0.4496\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 6.7848 - accuracy: 0.0836\n",
      "\n",
      " Epochs: 100 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1538 - accuracy: 0.4490\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.0121 - accuracy: 0.4551\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.3882 - accuracy: 0.4300\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.4306 - accuracy: 0.4346\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.3196 - accuracy: 0.4409\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 6.4768 - accuracy: 0.0788\n",
      "\n",
      " Epochs: 105 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.3492 - accuracy: 0.4407\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2797 - accuracy: 0.4522\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.3043 - accuracy: 0.4503\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2711 - accuracy: 0.4461\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1373 - accuracy: 0.4577\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 6.5540 - accuracy: 0.0827\n",
      "\n",
      " Epochs: 110 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2614 - accuracy: 0.4511\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2359 - accuracy: 0.4522\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1198 - accuracy: 0.4599\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2522 - accuracy: 0.4509\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2541 - accuracy: 0.4522\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 6.8354 - accuracy: 0.0794\n",
      "\n",
      " Epochs: 115 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2867 - accuracy: 0.4522\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1519 - accuracy: 0.4594\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.3338 - accuracy: 0.4505\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2014 - accuracy: 0.4603\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.0854 - accuracy: 0.4662\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 6.9973 - accuracy: 0.0854\n",
      "\n",
      " Epochs: 120 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1039 - accuracy: 0.4529\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2222 - accuracy: 0.4494\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1082 - accuracy: 0.4603\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1870 - accuracy: 0.4603\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2762 - accuracy: 0.4459\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 6.5975 - accuracy: 0.0741\n",
      "\n",
      " Epochs: 125 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2100 - accuracy: 0.4524\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2369 - accuracy: 0.4581\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1387 - accuracy: 0.4631\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1136 - accuracy: 0.4675\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2699 - accuracy: 0.4583\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 6.8753 - accuracy: 0.0810\n",
      "\n",
      " Epochs: 130 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2300 - accuracy: 0.4594\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2189 - accuracy: 0.4625\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.2654 - accuracy: 0.4542\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1119 - accuracy: 0.4644\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2611 - accuracy: 0.4557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 2s 11ms/step - loss: 7.4134 - accuracy: 0.0841\n",
      "\n",
      " Epochs: 135 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.1296 - accuracy: 0.4640\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0077 - accuracy: 0.4780\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2071 - accuracy: 0.4638\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.3671 - accuracy: 0.4557\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2792 - accuracy: 0.4586\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 7.4343 - accuracy: 0.0845\n",
      "\n",
      " Epochs: 140 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.5051 - accuracy: 0.4422\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.0294 - accuracy: 0.4719\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2684 - accuracy: 0.4559\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.2154 - accuracy: 0.4607\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.3869 - accuracy: 0.4544\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 7.3624 - accuracy: 0.0852\n",
      "\n",
      " Epochs: 145 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1681 - accuracy: 0.4673\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.0700 - accuracy: 0.4705\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.4003 - accuracy: 0.4544\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 7.8398 - accuracy: 0.4834\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 8.2615 - accuracy: 0.4531\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 7.4549 - accuracy: 0.0786\n",
      "\n",
      " Epochs: 150 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1508 - accuracy: 0.4586\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.1268 - accuracy: 0.4658\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2415 - accuracy: 0.4596\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.0318 - accuracy: 0.4697\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1342 - accuracy: 0.4710\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 7.1789 - accuracy: 0.0799\n",
      "\n",
      " Epochs: 155 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.0759 - accuracy: 0.4760\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2947 - accuracy: 0.4588\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 36ms/step - loss: 8.2795 - accuracy: 0.4618\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.3763 - accuracy: 0.4572\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 7.9813 - accuracy: 0.4729\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 7.5695 - accuracy: 0.0794\n",
      "\n",
      " Epochs: 160 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1439 - accuracy: 0.4712\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2363 - accuracy: 0.4673\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2817 - accuracy: 0.4634\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1488 - accuracy: 0.4677\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0554 - accuracy: 0.4769\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 7.8628 - accuracy: 0.0823\n",
      "\n",
      " Epochs: 165 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1213 - accuracy: 0.4747\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1793 - accuracy: 0.4686\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0770 - accuracy: 0.4786\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1453 - accuracy: 0.4677\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2361 - accuracy: 0.4692\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 7.5497 - accuracy: 0.0810\n",
      "\n",
      " Epochs: 170 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 7.9222 - accuracy: 0.4876\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2689 - accuracy: 0.4664\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.3154 - accuracy: 0.4644\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.3664 - accuracy: 0.4184\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.4245 - accuracy: 0.4169\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 7.9815 - accuracy: 0.0830\n",
      "\n",
      " Epochs: 175 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1992 - accuracy: 0.4466\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 7.9840 - accuracy: 0.4734\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.3080 - accuracy: 0.4557\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.2379 - accuracy: 0.4603\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2404 - accuracy: 0.4625\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 7.5482 - accuracy: 0.0805\n",
      "\n",
      " Epochs: 180 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1775 - accuracy: 0.4695\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.2333 - accuracy: 0.4684\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0221 - accuracy: 0.4828\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2491 - accuracy: 0.4675\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 7.8230 - accuracy: 0.4961\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 7.8412 - accuracy: 0.0794\n",
      "\n",
      " Epochs: 185 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.2549 - accuracy: 0.4662\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.2174 - accuracy: 0.4729\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 7.9056 - accuracy: 0.4891\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0862 - accuracy: 0.4799\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.2903 - accuracy: 0.4690\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 7.7356 - accuracy: 0.0790 0s -\n",
      "\n",
      " Epochs: 190 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2093 - accuracy: 0.4701\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 8.1584 - accuracy: 0.4771\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1794 - accuracy: 0.4716\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0499 - accuracy: 0.4832\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2071 - accuracy: 0.4695\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 7.8054 - accuracy: 0.0808\n",
      "\n",
      " Epochs: 195 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0663 - accuracy: 0.4788\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1641 - accuracy: 0.4740\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0637 - accuracy: 0.4788\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1606 - accuracy: 0.4745\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0445 - accuracy: 0.4834\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.3488 - accuracy: 0.0781\n",
      "\n",
      " Epochs: 200 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1760 - accuracy: 0.4747\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 7.9057 - accuracy: 0.4911\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0385 - accuracy: 0.4849\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.0360 - accuracy: 0.4834\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1641 - accuracy: 0.4738\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.3564 - accuracy: 0.0816\n",
      "\n",
      " Epochs: 205 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 7.9912 - accuracy: 0.4865\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.0731 - accuracy: 0.4825\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0847 - accuracy: 0.4784\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1719 - accuracy: 0.4721\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1743 - accuracy: 0.4699\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 7.9265 - accuracy: 0.0757\n",
      "\n",
      " Epochs: 210 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.3325 - accuracy: 0.4594\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2526 - accuracy: 0.4647\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.1666 - accuracy: 0.4705\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0780 - accuracy: 0.4815\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2438 - accuracy: 0.4732\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 7.9516 - accuracy: 0.0819\n",
      "\n",
      " Epochs: 215 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2342 - accuracy: 0.4758\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0586 - accuracy: 0.4841\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.0601 - accuracy: 0.4871\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0742 - accuracy: 0.4821\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.2565 - accuracy: 0.4705\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.5235 - accuracy: 0.0808\n",
      "\n",
      " Epochs: 220 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2240 - accuracy: 0.4719\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.3131 - accuracy: 0.4701\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.2067 - accuracy: 0.4760\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.0517 - accuracy: 0.4823\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.1047 - accuracy: 0.4788\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.1478 - accuracy: 0.0711\n",
      "\n",
      " Epochs: 225 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.0392 - accuracy: 0.4825\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2317 - accuracy: 0.4725\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 7.9927 - accuracy: 0.4882\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 37ms/step - loss: 8.2256 - accuracy: 0.4758\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0192 - accuracy: 0.4858\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 7.9819 - accuracy: 0.0759\n",
      "\n",
      " Epochs: 230 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2464 - accuracy: 0.4701\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.3700 - accuracy: 0.4616\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1599 - accuracy: 0.4753\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 7.9194 - accuracy: 0.4941\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2998 - accuracy: 0.4686\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.4353 - accuracy: 0.0823\n",
      "\n",
      " Epochs: 235 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.3301 - accuracy: 0.4668\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1219 - accuracy: 0.4823\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1382 - accuracy: 0.4799\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1188 - accuracy: 0.4815\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1583 - accuracy: 0.4784\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.4640 - accuracy: 0.0845\n",
      "\n",
      " Epochs: 240 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.3288 - accuracy: 0.4638\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0259 - accuracy: 0.4825\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2399 - accuracy: 0.4751\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0553 - accuracy: 0.4856\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1963 - accuracy: 0.4745\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.2873 - accuracy: 0.0832\n",
      "\n",
      " Epochs: 245 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0453 - accuracy: 0.4812\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0398 - accuracy: 0.4806\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0497 - accuracy: 0.4812\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.3245 - accuracy: 0.4682\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2255 - accuracy: 0.4734\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.1324 - accuracy: 0.0768\n",
      "\n",
      " Epochs: 250 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1772 - accuracy: 0.4773\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2055 - accuracy: 0.4758\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.2320 - accuracy: 0.4703\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.1413 - accuracy: 0.4793\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1899 - accuracy: 0.4749\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.5407 - accuracy: 0.0799\n",
      "\n",
      " Epochs: 255 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.2771 - accuracy: 0.4708\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0888 - accuracy: 0.4828\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.3020 - accuracy: 0.4686\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1395 - accuracy: 0.4775\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0183 - accuracy: 0.4871\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.4932 - accuracy: 0.0761\n",
      "\n",
      " Epochs: 260 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0768 - accuracy: 0.4836\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.2070 - accuracy: 0.4758\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.8066 - accuracy: 0.5020\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2351 - accuracy: 0.4753\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1282 - accuracy: 0.4801\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.4176 - accuracy: 0.0788\n",
      "\n",
      " Epochs: 265 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2054 - accuracy: 0.4756\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 7.9326 - accuracy: 0.4911\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2376 - accuracy: 0.4756\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9540 - accuracy: 0.4930\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 7.9449 - accuracy: 0.4937\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.2621 - accuracy: 0.0733\n",
      "\n",
      " Epochs: 270 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.3833 - accuracy: 0.4660\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1285 - accuracy: 0.4795\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0226 - accuracy: 0.4895\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0301 - accuracy: 0.4913\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0519 - accuracy: 0.4854\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 10.1965 - accuracy: 0.0763\n",
      "\n",
      " Epochs: 275 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2037 - accuracy: 0.4762\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0439 - accuracy: 0.4869\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1084 - accuracy: 0.4839\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1933 - accuracy: 0.4799\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 7.9736 - accuracy: 0.4941\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 10.0678 - accuracy: 0.0763\n",
      "\n",
      " Epochs: 280 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0968 - accuracy: 0.4836\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.8959 - accuracy: 0.4974\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0706 - accuracy: 0.4858\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0363 - accuracy: 0.4891\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1095 - accuracy: 0.4828\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.6164 - accuracy: 0.0686\n",
      "\n",
      " Epochs: 285 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0927 - accuracy: 0.4830\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0897 - accuracy: 0.4884\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0478 - accuracy: 0.4878\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.2235 - accuracy: 0.4723\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2295 - accuracy: 0.4736\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.7992 - accuracy: 0.0781\n",
      "\n",
      " Epochs: 290 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.1215 - accuracy: 0.4828\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0620 - accuracy: 0.4856\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0493 - accuracy: 0.4902\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.3150 - accuracy: 0.4714\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1952 - accuracy: 0.4769\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.2916 - accuracy: 0.0781\n",
      "\n",
      " Epochs: 295 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1928 - accuracy: 0.4771\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1894 - accuracy: 0.4795\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1358 - accuracy: 0.4808\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0203 - accuracy: 0.4893\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0311 - accuracy: 0.4834\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.8957 - accuracy: 0.0713\n",
      "\n",
      " Epochs: 300 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0729 - accuracy: 0.4860\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.1732 - accuracy: 0.4760\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2862 - accuracy: 0.4692\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0907 - accuracy: 0.4819\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9180 - accuracy: 0.4928\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.5643 - accuracy: 0.0750\n",
      "\n",
      " Epochs: 305 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1845 - accuracy: 0.4773\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.4126 - accuracy: 0.4655\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1654 - accuracy: 0.4767\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0043 - accuracy: 0.4932\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0801 - accuracy: 0.4878\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 9.1275 - accuracy: 0.0801\n",
      "\n",
      " Epochs: 310 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9734 - accuracy: 0.4895\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9544 - accuracy: 0.4956\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0579 - accuracy: 0.4867\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1108 - accuracy: 0.4845\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1515 - accuracy: 0.4810\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.5604 - accuracy: 0.0772\n",
      "\n",
      " Epochs: 315 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0770 - accuracy: 0.4893\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 7.9945 - accuracy: 0.4917\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9004 - accuracy: 0.4983\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1878 - accuracy: 0.4817\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0114 - accuracy: 0.4900\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.7810 - accuracy: 0.0779\n",
      "\n",
      " Epochs: 320 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1922 - accuracy: 0.4797\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 8.2278 - accuracy: 0.4764\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1077 - accuracy: 0.4854\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1615 - accuracy: 0.4825\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.3778 - accuracy: 0.4673\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.9808 - accuracy: 0.0768\n",
      "\n",
      " Epochs: 325 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0348 - accuracy: 0.4913\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.3111 - accuracy: 0.4716\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1123 - accuracy: 0.4839\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9636 - accuracy: 0.4937\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9016 - accuracy: 0.4974\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 9.1833 - accuracy: 0.0777\n",
      "\n",
      " Epochs: 330 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0544 - accuracy: 0.4876\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0823 - accuracy: 0.4897\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1988 - accuracy: 0.4786\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1343 - accuracy: 0.4845\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9839 - accuracy: 0.4954\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 12.2012 - accuracy: 0.0635\n",
      "\n",
      " Epochs: 335 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0452 - accuracy: 0.4904\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0157 - accuracy: 0.4921\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 6s 38ms/step - loss: 8.3428 - accuracy: 0.4644\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.2142 - accuracy: 0.4708\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2984 - accuracy: 0.4703\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 8.9718 - accuracy: 0.0810\n",
      "\n",
      " Epochs: 340 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0787 - accuracy: 0.4832\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.1479 - accuracy: 0.4782\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1675 - accuracy: 0.4791\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.1729 - accuracy: 0.4771\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9218 - accuracy: 0.4943\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.3435 - accuracy: 0.0779\n",
      "\n",
      " Epochs: 345 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2205 - accuracy: 0.4758\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0995 - accuracy: 0.4793\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.3585 - accuracy: 0.4692\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 7.9916 - accuracy: 0.4937\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.1755 - accuracy: 0.4806\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 10.1794 - accuracy: 0.0792\n",
      "\n",
      " Epochs: 350 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9267 - accuracy: 0.4972\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2699 - accuracy: 0.4729\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.2136 - accuracy: 0.4801\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0016 - accuracy: 0.4926\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2377 - accuracy: 0.4815\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.3311 - accuracy: 0.0766\n",
      "\n",
      " Epochs: 355 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0610 - accuracy: 0.4911\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 7.9890 - accuracy: 0.4926\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.1142 - accuracy: 0.4839\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1996 - accuracy: 0.4815\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1145 - accuracy: 0.4834\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 9.0585 - accuracy: 0.0788\n",
      "\n",
      " Epochs: 360 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0566 - accuracy: 0.4900\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1660 - accuracy: 0.4812\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.3041 - accuracy: 0.4712\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9785 - accuracy: 0.4930\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9952 - accuracy: 0.4926\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 10.0889 - accuracy: 0.0722\n",
      "\n",
      " Epochs: 365 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9621 - accuracy: 0.4954\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9781 - accuracy: 0.4928\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2218 - accuracy: 0.4797\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.1584 - accuracy: 0.4806\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0289 - accuracy: 0.4891\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 9.5008 - accuracy: 0.0792\n",
      "\n",
      " Epochs: 370 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0265 - accuracy: 0.4902\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0933 - accuracy: 0.4836\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1251 - accuracy: 0.4830\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.4176 - accuracy: 0.4673\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2651 - accuracy: 0.4767\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 9.4100 - accuracy: 0.0766\n",
      "\n",
      " Epochs: 375 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0890 - accuracy: 0.4871\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0755 - accuracy: 0.4858\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0842 - accuracy: 0.4897\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 7.9255 - accuracy: 0.4969\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.1227 - accuracy: 0.4841\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 8.9382 - accuracy: 0.0735\n",
      "\n",
      " Epochs: 380 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 7.9569 - accuracy: 0.4941\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1514 - accuracy: 0.4830\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9088 - accuracy: 0.4976\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1193 - accuracy: 0.4841\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1373 - accuracy: 0.4871\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 9.2258 - accuracy: 0.0768: 1s - loss: 9.6 - ETA: \n",
      "\n",
      " Epochs: 385 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1933 - accuracy: 0.4828\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0866 - accuracy: 0.4887\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1406 - accuracy: 0.4825\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9963 - accuracy: 0.4926\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.3979 - accuracy: 0.4708\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 9.4889 - accuracy: 0.0739\n",
      "\n",
      " Epochs: 390 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9597 - accuracy: 0.4972\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.2370 - accuracy: 0.4782\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.8149 - accuracy: 0.5068\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.8748 - accuracy: 0.5015\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 7.8241 - accuracy: 0.5033\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 9.7352 - accuracy: 0.0766\n",
      "\n",
      " Epochs: 395 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0699 - accuracy: 0.4876\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0202 - accuracy: 0.4943\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.1472 - accuracy: 0.4849\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0974 - accuracy: 0.4908\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0748 - accuracy: 0.4871\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 9.5824 - accuracy: 0.0786\n",
      "\n",
      " Epochs: 400 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9681 - accuracy: 0.4930\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1487 - accuracy: 0.4823\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.2704 - accuracy: 0.4758\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1038 - accuracy: 0.4847\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0361 - accuracy: 0.4919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 2s 12ms/step - loss: 9.4334 - accuracy: 0.0763\n",
      "\n",
      " Epochs: 405 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1534 - accuracy: 0.4815\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0568 - accuracy: 0.4911\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 7.9454 - accuracy: 0.4961\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1692 - accuracy: 0.4839\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0632 - accuracy: 0.4860\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 9.7824 - accuracy: 0.0761\n",
      "\n",
      " Epochs: 410 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 7.9733 - accuracy: 0.4950\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0524 - accuracy: 0.4935\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9617 - accuracy: 0.4959\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 8.0910 - accuracy: 0.4863\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2754 - accuracy: 0.4767\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.2705 - accuracy: 0.0759\n",
      "\n",
      " Epochs: 415 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0124 - accuracy: 0.4939\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.8839 - accuracy: 0.4998\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0146 - accuracy: 0.4928\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 7.9995 - accuracy: 0.4965\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9742 - accuracy: 0.4943\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 10.0660 - accuracy: 0.0741\n",
      "\n",
      " Epochs: 420 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0993 - accuracy: 0.4878\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.2736 - accuracy: 0.4780\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0576 - accuracy: 0.4895\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2463 - accuracy: 0.4769\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0732 - accuracy: 0.4880\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.3651 - accuracy: 0.0803\n",
      "\n",
      " Epochs: 425 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1813 - accuracy: 0.4839\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0995 - accuracy: 0.4882\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1263 - accuracy: 0.4849\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2373 - accuracy: 0.4784\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.1015 - accuracy: 0.4878\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.4141 - accuracy: 0.0774\n",
      "\n",
      " Epochs: 430 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2110 - accuracy: 0.4823\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 7.9794 - accuracy: 0.4972\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9913 - accuracy: 0.4965\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1792 - accuracy: 0.4845\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1413 - accuracy: 0.4869\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.0665 - accuracy: 0.0797\n",
      "\n",
      " Epochs: 435 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9865 - accuracy: 0.4952\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0516 - accuracy: 0.4915\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1733 - accuracy: 0.4830\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1528 - accuracy: 0.4860\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 38ms/step - loss: 8.0415 - accuracy: 0.4948\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 9.1814 - accuracy: 0.0843\n",
      "\n",
      " Epochs: 440 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2233 - accuracy: 0.4808\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0134 - accuracy: 0.4913\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0762 - accuracy: 0.4911\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0910 - accuracy: 0.4911\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2040 - accuracy: 0.4793\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.6213 - accuracy: 0.0763\n",
      "\n",
      " Epochs: 445 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9062 - accuracy: 0.4998\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9613 - accuracy: 0.4954\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1274 - accuracy: 0.4854\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0721 - accuracy: 0.4889\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2190 - accuracy: 0.4815\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.4558 - accuracy: 0.0772\n",
      "\n",
      " Epochs: 450 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0946 - accuracy: 0.4841\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0869 - accuracy: 0.4847\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2656 - accuracy: 0.4767\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.4241 - accuracy: 0.4675\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2264 - accuracy: 0.4793\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.1658 - accuracy: 0.0841\n",
      "\n",
      " Epochs: 455 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1870 - accuracy: 0.4854\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1105 - accuracy: 0.4893\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.8497 - accuracy: 0.5028\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0197 - accuracy: 0.4950\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0733 - accuracy: 0.4887\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.5773 - accuracy: 0.0781\n",
      "\n",
      " Epochs: 460 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1977 - accuracy: 0.4847\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0305 - accuracy: 0.4948\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2679 - accuracy: 0.4791\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9093 - accuracy: 0.5011\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9919 - accuracy: 0.4965\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.3399 - accuracy: 0.0808\n",
      "\n",
      " Epochs: 465 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0929 - accuracy: 0.4895\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2188 - accuracy: 0.4801\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9606 - accuracy: 0.4991\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0588 - accuracy: 0.4915\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0082 - accuracy: 0.4939\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.6079 - accuracy: 0.0717\n",
      "\n",
      " Epochs: 470 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2524 - accuracy: 0.4784\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1560 - accuracy: 0.4856\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0825 - accuracy: 0.4839\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9861 - accuracy: 0.4939\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0666 - accuracy: 0.4897\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.5302 - accuracy: 0.0708\n",
      "\n",
      " Epochs: 475 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1775 - accuracy: 0.4845\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1573 - accuracy: 0.4867\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2509 - accuracy: 0.4801\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9941 - accuracy: 0.4930\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9374 - accuracy: 0.4972\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.8008 - accuracy: 0.0719\n",
      "\n",
      " Epochs: 480 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.8698 - accuracy: 0.5022\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1372 - accuracy: 0.4852\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1564 - accuracy: 0.4854\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0669 - accuracy: 0.4924\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0061 - accuracy: 0.4954\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.5376 - accuracy: 0.0724\n",
      "\n",
      " Epochs: 485 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1126 - accuracy: 0.4891\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0666 - accuracy: 0.4926\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0508 - accuracy: 0.4943\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0050 - accuracy: 0.4972\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0789 - accuracy: 0.4913\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.4215 - accuracy: 0.0719\n",
      "\n",
      " Epochs: 490 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2785 - accuracy: 0.4760\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1461 - accuracy: 0.4854\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.8860 - accuracy: 0.5022\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2615 - accuracy: 0.4784\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0602 - accuracy: 0.4917\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.8761 - accuracy: 0.0801\n",
      "\n",
      " Epochs: 495 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2039 - accuracy: 0.4819\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1757 - accuracy: 0.4849\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0797 - accuracy: 0.4869\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1034 - accuracy: 0.4902\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0275 - accuracy: 0.4928\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.4458 - accuracy: 0.0774\n",
      "\n",
      " Epochs: 500 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1078 - accuracy: 0.4873\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0155 - accuracy: 0.4987\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0344 - accuracy: 0.4945\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0860 - accuracy: 0.4911\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 7.9579 - accuracy: 0.4987\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.3642 - accuracy: 0.0783\n",
      "\n",
      " Epochs: 505 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.1293 - accuracy: 0.4860\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9064 - accuracy: 0.5009\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9688 - accuracy: 0.4987\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2712 - accuracy: 0.4797\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9307 - accuracy: 0.5022\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.8818 - accuracy: 0.0783\n",
      "\n",
      " Epochs: 510 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9225 - accuracy: 0.5011\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9506 - accuracy: 0.4996\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0729 - accuracy: 0.4893\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0394 - accuracy: 0.4921\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2052 - accuracy: 0.4843\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.7838 - accuracy: 0.0819\n",
      "\n",
      " Epochs: 515 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 8.2427 - accuracy: 0.4808\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1765 - accuracy: 0.4845\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0174 - accuracy: 0.4943\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9536 - accuracy: 0.4978\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0053 - accuracy: 0.4963\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.7683 - accuracy: 0.0850\n",
      "\n",
      " Epochs: 520 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.2168 - accuracy: 0.4841\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 9s 60ms/step - loss: 8.2453 - accuracy: 0.4815\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9064 - accuracy: 0.5022\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0967 - accuracy: 0.4906\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1043 - accuracy: 0.4865\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 10.1846 - accuracy: 0.0777\n",
      "\n",
      " Epochs: 525 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9001 - accuracy: 0.5033\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1092 - accuracy: 0.4908\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9632 - accuracy: 0.4993\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 7.9441 - accuracy: 0.4987\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1595 - accuracy: 0.4867\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 9.7055 - accuracy: 0.0792\n",
      "\n",
      " Epochs: 530 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 39ms/step - loss: 8.0361 - accuracy: 0.4919\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.3906 - accuracy: 0.4714\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1598 - accuracy: 0.4865\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0497 - accuracy: 0.4945\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1330 - accuracy: 0.4887\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.3789 - accuracy: 0.0786\n",
      "\n",
      " Epochs: 535 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1627 - accuracy: 0.4863\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1630 - accuracy: 0.4849\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.2226 - accuracy: 0.4815\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1309 - accuracy: 0.4856\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0990 - accuracy: 0.4847\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.7086 - accuracy: 0.0799\n",
      "\n",
      " Epochs: 540 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2144 - accuracy: 0.4828\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1285 - accuracy: 0.4871\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0878 - accuracy: 0.4889\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0810 - accuracy: 0.4871\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0600 - accuracy: 0.4913\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.5727 - accuracy: 0.0759\n",
      "\n",
      " Epochs: 545 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0127 - accuracy: 0.4954\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0172 - accuracy: 0.4950\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.2633 - accuracy: 0.4799\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1522 - accuracy: 0.4843\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2098 - accuracy: 0.4821\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.8486 - accuracy: 0.0733\n",
      "\n",
      " Epochs: 550 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9991 - accuracy: 0.4961\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.1702 - accuracy: 0.4839\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 7.9290 - accuracy: 0.5020\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1173 - accuracy: 0.4871\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1283 - accuracy: 0.4884\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.5979 - accuracy: 0.0781\n",
      "\n",
      " Epochs: 555 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.2145 - accuracy: 0.4834\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9112 - accuracy: 0.4993\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1295 - accuracy: 0.4882\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1449 - accuracy: 0.4847\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2519 - accuracy: 0.4793\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.8724 - accuracy: 0.0790\n",
      "\n",
      " Epochs: 560 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1870 - accuracy: 0.4865\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9723 - accuracy: 0.5009\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0993 - accuracy: 0.4917\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0267 - accuracy: 0.4963\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1525 - accuracy: 0.4869\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.5873 - accuracy: 0.0781\n",
      "\n",
      " Epochs: 565 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1068 - accuracy: 0.4902\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.8861 - accuracy: 0.5024\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 8.1078 - accuracy: 0.4873\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1431 - accuracy: 0.4871\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 7.9717 - accuracy: 0.4976\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 9.7176 - accuracy: 0.0759\n",
      "\n",
      " Epochs: 570 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.2429 - accuracy: 0.4819\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1530 - accuracy: 0.4852\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.2133 - accuracy: 0.4819\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1854 - accuracy: 0.4854\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1087 - accuracy: 0.4895\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 9.4891 - accuracy: 0.0792\n",
      "\n",
      " Epochs: 575 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.2080 - accuracy: 0.4825\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0690 - accuracy: 0.4913\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.2918 - accuracy: 0.4793\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1521 - accuracy: 0.4880\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1298 - accuracy: 0.4895\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 9.8330 - accuracy: 0.0850\n",
      "\n",
      " Epochs: 580 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1146 - accuracy: 0.4904\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0236 - accuracy: 0.4956\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1919 - accuracy: 0.4858\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.8943 - accuracy: 0.5044\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9906 - accuracy: 0.4974\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 9.8454 - accuracy: 0.0834\n",
      "\n",
      " Epochs: 585 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0263 - accuracy: 0.4961\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.2248 - accuracy: 0.4843\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 8.1922 - accuracy: 0.4843\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9447 - accuracy: 0.4963\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1243 - accuracy: 0.4858\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 9.4713 - accuracy: 0.0755\n",
      "\n",
      " Epochs: 590 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.9971 - accuracy: 0.4985\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.8903 - accuracy: 0.5041\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0421 - accuracy: 0.4928\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1635 - accuracy: 0.4852\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.7961 - accuracy: 0.5098\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 9.7486 - accuracy: 0.0772\n",
      "\n",
      " Epochs: 595 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0728 - accuracy: 0.4893\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1214 - accuracy: 0.4904\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 7.9759 - accuracy: 0.4983\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0584 - accuracy: 0.4926\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1501 - accuracy: 0.4865\n",
      "142/142 [==============================] - 4s 28ms/step - loss: 9.9981 - accuracy: 0.0781\n",
      "\n",
      " Epochs: 600 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 7.8929 - accuracy: 0.5037\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9886 - accuracy: 0.4976\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.2101 - accuracy: 0.4821\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.0615 - accuracy: 0.4917\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1733 - accuracy: 0.4841\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.6514 - accuracy: 0.0816\n",
      "\n",
      " Epochs: 605 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9127 - accuracy: 0.5017\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9528 - accuracy: 0.4987\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.3646 - accuracy: 0.4734\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.2341 - accuracy: 0.4834\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1273 - accuracy: 0.4882\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 9.8877 - accuracy: 0.0812A: 2s - \n",
      "\n",
      " Epochs: 610 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.2210 - accuracy: 0.4817\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9075 - accuracy: 0.5031\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 7.9864 - accuracy: 0.4980\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1658 - accuracy: 0.4858\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.2307 - accuracy: 0.4808\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.7859 - accuracy: 0.0744 0s - los\n",
      "\n",
      " Epochs: 615 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1098 - accuracy: 0.4904\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9445 - accuracy: 0.4991\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0154 - accuracy: 0.4961\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9445 - accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0331 - accuracy: 0.4948\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.8148 - accuracy: 0.0750\n",
      "\n",
      " Epochs: 620 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1256 - accuracy: 0.4904\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0388 - accuracy: 0.4954\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0493 - accuracy: 0.4928\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 40ms/step - loss: 8.1259 - accuracy: 0.4884\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1378 - accuracy: 0.4882\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 10.1299 - accuracy: 0.0794\n",
      "\n",
      " Epochs: 625 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1028 - accuracy: 0.4904\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0834 - accuracy: 0.4924\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 7.9627 - accuracy: 0.4998\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 7.9827 - accuracy: 0.4956\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 7.8780 - accuracy: 0.5063\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.6984 - accuracy: 0.0790\n",
      "\n",
      " Epochs: 630 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1052 - accuracy: 0.4904\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.2004 - accuracy: 0.4860\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0280 - accuracy: 0.4954\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1626 - accuracy: 0.4871\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0959 - accuracy: 0.4921\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.5791 - accuracy: 0.0750\n",
      "\n",
      " Epochs: 635 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1801 - accuracy: 0.4871\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0863 - accuracy: 0.4926\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9822 - accuracy: 0.4980\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0873 - accuracy: 0.4915 1s -\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 7.9672 - accuracy: 0.4972\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.9791 - accuracy: 0.0755\n",
      "\n",
      " Epochs: 640 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0203 - accuracy: 0.4963\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0876 - accuracy: 0.4937\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.8907 - accuracy: 0.5050\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0065 - accuracy: 0.4976\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1147 - accuracy: 0.4893\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 9.8184 - accuracy: 0.0735A:\n",
      "\n",
      " Epochs: 645 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0004 - accuracy: 0.4963\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0042 - accuracy: 0.4963\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9919 - accuracy: 0.4972\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9224 - accuracy: 0.5028\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1015 - accuracy: 0.4908\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.9607 - accuracy: 0.0788\n",
      "\n",
      " Epochs: 650 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0563 - accuracy: 0.4943\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 7.9683 - accuracy: 0.4987\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 7.9973 - accuracy: 0.4985\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0517 - accuracy: 0.4935\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0869 - accuracy: 0.4924\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 10.2585 - accuracy: 0.0830\n",
      "\n",
      " Epochs: 655 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 7.8991 - accuracy: 0.5039\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0012 - accuracy: 0.4991\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 7.9305 - accuracy: 0.4976\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.3657 - accuracy: 0.4660\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 7.9998 - accuracy: 0.4932\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.8160 - accuracy: 0.0834\n",
      "\n",
      " Epochs: 660 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1027 - accuracy: 0.4904\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1116 - accuracy: 0.4897\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0314 - accuracy: 0.4952\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.0667 - accuracy: 0.4935\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1291 - accuracy: 0.4902\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 9.9751 - accuracy: 0.0841: 2s - loss: 10.1982 - accuracy: 0.106 \n",
      "\n",
      " Epochs: 665 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1439 - accuracy: 0.4871\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0619 - accuracy: 0.4930\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 7.9538 - accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.1060 - accuracy: 0.4928\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9744 - accuracy: 0.4996\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 9.7064 - accuracy: 0.0761\n",
      "\n",
      " Epochs: 670 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 7.9642 - accuracy: 0.4985\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1963 - accuracy: 0.4860\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1250 - accuracy: 0.4919\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 8.1935 - accuracy: 0.4871\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 7.9537 - accuracy: 0.5026\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 10.0495 - accuracy: 0.0810: 2s - loss: 10.2473 - accuracy: 0.091 - ETA: 2s - loss: \n",
      "\n",
      " Epochs: 675 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 8.1180 - accuracy: 0.4928\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1813 - accuracy: 0.4856\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0031 - accuracy: 0.4952\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0869 - accuracy: 0.4930\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1296 - accuracy: 0.4897\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 10.0362 - accuracy: 0.0781\n",
      "\n",
      " Epochs: 680 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9138 - accuracy: 0.5037\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0520 - accuracy: 0.4965\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0164 - accuracy: 0.4983\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0350 - accuracy: 0.4956\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0465 - accuracy: 0.4937\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.0750 - accuracy: 0.0816: 2s\n",
      "\n",
      " Epochs: 685 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.0489 - accuracy: 0.4941\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.2787 - accuracy: 0.4795\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.2332 - accuracy: 0.4808\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1303 - accuracy: 0.4906\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 8.0448 - accuracy: 0.4939\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 10.4732 - accuracy: 0.0779\n",
      "\n",
      " Epochs: 690 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 8.0038 - accuracy: 0.4965\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 8.2474 - accuracy: 0.4817 1s - loss: 8.2665 - accuracy - ETA: 1s -\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9995 - accuracy: 0.4983\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.3150 - accuracy: 0.4777\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.2037 - accuracy: 0.4841\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.0743 - accuracy: 0.0713\n",
      "\n",
      " Epochs: 695 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 7.9349 - accuracy: 0.5035\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0577 - accuracy: 0.4941\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0916 - accuracy: 0.4926\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 7.8866 - accuracy: 0.5046\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.1249 - accuracy: 0.4911\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.1479 - accuracy: 0.0735\n",
      "\n",
      " Epochs: 700 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1589 - accuracy: 0.4869\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.0981 - accuracy: 0.4913\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1213 - accuracy: 0.4880\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 7.9746 - accuracy: 0.4967\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1494 - accuracy: 0.4863\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.0471 - accuracy: 0.0741\n",
      "\n",
      " Epochs: 705 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1348 - accuracy: 0.4889\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 8.1850 - accuracy: 0.4863\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.2957 - accuracy: 0.4808\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 8.0717 - accuracy: 0.4937\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0838 - accuracy: 0.4917\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.0999 - accuracy: 0.0715\n",
      "\n",
      " Epochs: 710 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 7.9681 - accuracy: 0.4993\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 8.2225 - accuracy: 0.4836\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1674 - accuracy: 0.4882\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 7.8592 - accuracy: 0.5063\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1195 - accuracy: 0.4906\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.2279 - accuracy: 0.0770\n",
      "\n",
      " Epochs: 715 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.0935 - accuracy: 0.4911\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1369 - accuracy: 0.4906\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.2289 - accuracy: 0.4843\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.2200 - accuracy: 0.4854\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0374 - accuracy: 0.4974\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.1334 - accuracy: 0.0739\n",
      "\n",
      " Epochs: 720 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.0418 - accuracy: 0.4969\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 7.9125 - accuracy: 0.5026\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 7.9213 - accuracy: 0.5011\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 7.9841 - accuracy: 0.4983\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0759 - accuracy: 0.4919\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 10.0448 - accuracy: 0.0748\n",
      "\n",
      " Epochs: 725 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1938 - accuracy: 0.4839\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 7.9043 - accuracy: 0.5044\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.1725 - accuracy: 0.4876\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 7.9962 - accuracy: 0.4976\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1581 - accuracy: 0.4878\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 9.9612 - accuracy: 0.0739\n",
      "\n",
      " Epochs: 730 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.3787 - accuracy: 0.4745\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.2076 - accuracy: 0.4832\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.1576 - accuracy: 0.4884\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.1342 - accuracy: 0.4915\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 8.1710 - accuracy: 0.4871\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.1763 - accuracy: 0.0772\n",
      "\n",
      " Epochs: 735 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 7.9568 - accuracy: 0.5009\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 7.9063 - accuracy: 0.5022\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 8.3771 - accuracy: 0.4745\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.0449 - accuracy: 0.4948\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 8.0743 - accuracy: 0.4937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 2s 15ms/step - loss: 10.2639 - accuracy: 0.0702: 0s - loss: 10.2341 - accurac\n",
      "\n",
      " Epochs: 740 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.0136 - accuracy: 0.4974\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 7.8706 - accuracy: 0.5065\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0558 - accuracy: 0.4928\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.1441 - accuracy: 0.4871\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1190 - accuracy: 0.4895\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.5225 - accuracy: 0.0682\n",
      "\n",
      " Epochs: 745 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 8.1826 - accuracy: 0.4863\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 8.0534 - accuracy: 0.4928\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1239 - accuracy: 0.4873\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 8.0953 - accuracy: 0.4921\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0361 - accuracy: 0.4930\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.8040 - accuracy: 0.0781\n",
      "\n",
      " Epochs: 750 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 7.9651 - accuracy: 0.4996\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0995 - accuracy: 0.4915\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1264 - accuracy: 0.4882\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 7.9385 - accuracy: 0.5020\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0667 - accuracy: 0.4952\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 10.5348 - accuracy: 0.0777\n",
      "\n",
      " Epochs: 755 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 7.9422 - accuracy: 0.5022\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0235 - accuracy: 0.4976\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 8.0328 - accuracy: 0.4963\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0509 - accuracy: 0.4943\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.0813 - accuracy: 0.4932\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 10.2185 - accuracy: 0.0781: 1s -\n",
      "\n",
      " Epochs: 760 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 7.9969 - accuracy: 0.4985\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1019 - accuracy: 0.4928\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 8.1056 - accuracy: 0.4926\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0815 - accuracy: 0.4913\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 8.1176 - accuracy: 0.4908\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.3564 - accuracy: 0.0821\n",
      "\n",
      " Epochs: 765 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.2130 - accuracy: 0.4858\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.1256 - accuracy: 0.4893\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 7.9571 - accuracy: 0.5004\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 7.9270 - accuracy: 0.5015\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 7.7240 - accuracy: 0.5153\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.2460 - accuracy: 0.0794: 1s - loss: 10.5\n",
      "\n",
      " Epochs: 770 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.1766 - accuracy: 0.4884\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 8.2386 - accuracy: 0.4849\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 7.9516 - accuracy: 0.5011\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.0696 - accuracy: 0.4937\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 8.2125 - accuracy: 0.4871\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 10.3779 - accuracy: 0.0750: 1s\n",
      "\n",
      " Epochs: 775 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.0284 - accuracy: 0.4961 0s\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.1678 - accuracy: 0.4832\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.0547 - accuracy: 0.4948\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.1438 - accuracy: 0.4893\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1213 - accuracy: 0.4904\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 10.5614 - accuracy: 0.0808\n",
      "\n",
      " Epochs: 780 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.0641 - accuracy: 0.4930\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.3090 - accuracy: 0.4801\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.1887 - accuracy: 0.4873\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 7.9802 - accuracy: 0.4996\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1208 - accuracy: 0.4932\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 10.1225 - accuracy: 0.0781\n",
      "\n",
      " Epochs: 785 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 8.0082 - accuracy: 0.4989\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 8.0194 - accuracy: 0.4974\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 8.0444 - accuracy: 0.4963\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 7.9155 - accuracy: 0.5046\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.1225 - accuracy: 0.4902\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 10.1269 - accuracy: 0.0746: 1s - loss: 10.3\n",
      "\n",
      " Epochs: 790 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 8.0970 - accuracy: 0.4928\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 7.8283 - accuracy: 0.5098\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 8.0403 - accuracy: 0.4952\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.0115 - accuracy: 0.4978\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.0620 - accuracy: 0.4954\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 10.2884 - accuracy: 0.0772: 1s - loss\n",
      "\n",
      " Epochs: 795 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0065 - accuracy: 0.4972\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 7.9622 - accuracy: 0.5011\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 9s 61ms/step - loss: 8.0313 - accuracy: 0.4967\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 8.1547 - accuracy: 0.4873\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 57ms/step - loss: 8.2336 - accuracy: 0.4839\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 10.8700 - accuracy: 0.0788\n",
      "\n",
      " Epochs: 800 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 8.0432 - accuracy: 0.4950\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 9s 60ms/step - loss: 8.3769 - accuracy: 0.4751\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 10s 70ms/step - loss: 8.0354 - accuracy: 0.4950\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0421 - accuracy: 0.4943\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 8.2278 - accuracy: 0.4819\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.2099 - accuracy: 0.0750\n",
      "\n",
      " Epochs: 805 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0716 - accuracy: 0.4904\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0227 - accuracy: 0.4961\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.2161 - accuracy: 0.4839\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.1205 - accuracy: 0.4889\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 8.3495 - accuracy: 0.4762\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.3296 - accuracy: 0.0836\n",
      "\n",
      " Epochs: 810 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 7.9120 - accuracy: 0.5013\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.1259 - accuracy: 0.4884\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 7.9813 - accuracy: 0.5007\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 8.0551 - accuracy: 0.4937\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 7.9076 - accuracy: 0.5048\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 10.9451 - accuracy: 0.0821\n",
      "\n",
      " Epochs: 815 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 7.9954 - accuracy: 0.4978\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 8.0693 - accuracy: 0.4930\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 7.9710 - accuracy: 0.5011\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 8.0629 - accuracy: 0.4945\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 8.1357 - accuracy: 0.4895\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 10.2848 - accuracy: 0.0774\n",
      "\n",
      " Epochs: 820 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.2015 - accuracy: 0.4852\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 8.0339 - accuracy: 0.4972\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.2146 - accuracy: 0.4854\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 8.0705 - accuracy: 0.4961\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 8.2340 - accuracy: 0.4849\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 10.3233 - accuracy: 0.0797\n",
      "\n",
      " Epochs: 825 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 8.2079 - accuracy: 0.4871 0s - loss: 8.1855 \n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 8.0700 - accuracy: 0.4961\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 7.9818 - accuracy: 0.5007\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0460 - accuracy: 0.4941\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 7.9757 - accuracy: 0.4996\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 10.3588 - accuracy: 0.0772\n",
      "\n",
      " Epochs: 830 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 7.9991 - accuracy: 0.4974\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 8.2845 - accuracy: 0.4825\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 7.9707 - accuracy: 0.5022\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 10s 70ms/step - loss: 8.1047 - accuracy: 0.4913\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 9s 59ms/step - loss: 8.1601 - accuracy: 0.4873\n",
      "142/142 [==============================] - 7s 46ms/step - loss: 10.3591 - accuracy: 0.0794: 1s - loss:  - ETA: 0s - loss: 10.2960 - accuracy: 0.0 - ETA: 0s - loss: 10.2990 - accura - ETA: 0s - loss: 10.3420 - accuracy: 0\n",
      "\n",
      " Epochs: 835 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 11s 75ms/step - loss: 7.9978 - accuracy: 0.4996\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 8.0976 - accuracy: 0.4928\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 8.1714 - accuracy: 0.4882\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 7.9997 - accuracy: 0.4978\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 8.0023 - accuracy: 0.4983\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 10.7021 - accuracy: 0.0779\n",
      "\n",
      " Epochs: 840 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 8.0670 - accuracy: 0.4928\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 8.0321 - accuracy: 0.4972\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.1329 - accuracy: 0.4904\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 8.0153 - accuracy: 0.4963\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 8.0503 - accuracy: 0.4967\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 10.2484 - accuracy: 0.0823\n",
      "\n",
      " Epochs: 845 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 8.2176 - accuracy: 0.4863\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 8.0767 - accuracy: 0.4906\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 7.9216 - accuracy: 0.5022\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 7.9636 - accuracy: 0.4989\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 8.0281 - accuracy: 0.4980\n",
      "142/142 [==============================] - 3s 17ms/step - loss: 10.6828 - accuracy: 0.0752\n",
      "\n",
      " Epochs: 850 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 8.1460 - accuracy: 0.4900\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 8.0999 - accuracy: 0.4908\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 9s 65ms/step - loss: 8.0810 - accuracy: 0.4921\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 8.2151 - accuracy: 0.4854\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 8.1176 - accuracy: 0.4913\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 10.2438 - accuracy: 0.0777\n",
      "\n",
      " Epochs: 855 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 7.9806 - accuracy: 0.5020\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 41ms/step - loss: 8.1811 - accuracy: 0.4891\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0607 - accuracy: 0.4952\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0134 - accuracy: 0.4983\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 7.9019 - accuracy: 0.5050\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 10.1793 - accuracy: 0.0810: 0s - loss: 10.3088\n",
      "\n",
      " Epochs: 860 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1265 - accuracy: 0.4908\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 7.9993 - accuracy: 0.4989\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.0157 - accuracy: 0.4963\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.2454 - accuracy: 0.4828\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 7.9760 - accuracy: 0.4989\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 10.2877 - accuracy: 0.0816: 1s - loss: 10.4\n",
      "\n",
      " Epochs: 865 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.0385 - accuracy: 0.4972\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 42ms/step - loss: 8.0344 - accuracy: 0.4965\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 7.9498 - accuracy: 0.5024\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.1029 - accuracy: 0.4902\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 8.1870 - accuracy: 0.4869\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.4065 - accuracy: 0.0755: 1s - loss: \n",
      "\n",
      " Epochs: 870 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.1340 - accuracy: 0.4902\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 47ms/step - loss: 8.1226 - accuracy: 0.4917\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 6s 45ms/step - loss: 7.9479 - accuracy: 0.5022\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 8.0268 - accuracy: 0.4976\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 7.8636 - accuracy: 0.5083\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 10.3265 - accuracy: 0.0757\n",
      "\n",
      " Epochs: 875 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 8.2351 - accuracy: 0.4841\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 6s 44ms/step - loss: 8.1988 - accuracy: 0.4867\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.0753 - accuracy: 0.4945\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 7.8359 - accuracy: 0.5089\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 8.0736 - accuracy: 0.4941\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 10.4297 - accuracy: 0.0755\n",
      "\n",
      " Epochs: 880 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 8.1065 - accuracy: 0.4926\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 45ms/step - loss: 8.0551 - accuracy: 0.4963\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 8.0368 - accuracy: 0.4972\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 8.0705 - accuracy: 0.4948\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 8.0744 - accuracy: 0.4932\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 10.8211 - accuracy: 0.0814\n",
      "\n",
      " Epochs: 885 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 8.0380 - accuracy: 0.4963\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 7.8654 - accuracy: 0.5063\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 8.2997 - accuracy: 0.4821\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 46ms/step - loss: 8.1050 - accuracy: 0.4928\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 6s 43ms/step - loss: 8.0085 - accuracy: 0.4983\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 10.7189 - accuracy: 0.0819\n",
      "\n",
      " Epochs: 890 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 8.1164 - accuracy: 0.4902\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 8.0854 - accuracy: 0.4948\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 11s 76ms/step - loss: 8.1305 - accuracy: 0.48870s - loss: 8\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 8.1650 - accuracy: 0.4891\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 9s 61ms/step - loss: 8.1006 - accuracy: 0.4913\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 10.5307 - accuracy: 0.0783: 1s - loss: \n",
      "\n",
      " Epochs: 895 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 7.7474 - accuracy: 0.5133\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 8.1631 - accuracy: 0.4904\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 8.0083 - accuracy: 0.4987\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 7.9049 - accuracy: 0.5063\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 7.8784 - accuracy: 0.5061\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 10.3555 - accuracy: 0.0755: 1s - loss: 10.3239 - acc - ETA: 0s - loss: 10.2707 - accuracy: 0.\n",
      "\n",
      " Epochs: 900 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 8s 56ms/step - loss: 7.9298 - accuracy: 0.5022\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 8s 57ms/step - loss: 8.0358 - accuracy: 0.4954\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 7.9836 - accuracy: 0.4989\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 8.0932 - accuracy: 0.4928\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 7.9786 - accuracy: 0.4987\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 10.5524 - accuracy: 0.0797\n",
      "\n",
      " Epochs: 905 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 9s 61ms/step - loss: 7.8824 - accuracy: 0.5055\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 8.0503 - accuracy: 0.4956\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 8.0596 - accuracy: 0.4954\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 49ms/step - loss: 8.2982 - accuracy: 0.4793\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 8.0362 - accuracy: 0.4948\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 10.4563 - accuracy: 0.0744: 1s - loss: 10.65 - ETA: 0s - loss: 10.4522 - accuracy: 0.075\n",
      "\n",
      " Epochs: 910 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 8.0470 - accuracy: 0.4956\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 8.2244 - accuracy: 0.4852\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 50ms/step - loss: 7.8335 - accuracy: 0.5085\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 8.1038 - accuracy: 0.4939\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 8.3002 - accuracy: 0.4812\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 10.6282 - accuracy: 0.0781: 0s - loss: 10.6564 - a\n",
      "\n",
      " Epochs: 915 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 8s 56ms/step - loss: 7.9082 - accuracy: 0.5033\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 8.0828 - accuracy: 0.4945\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 8s 56ms/step - loss: 7.9646 - accuracy: 0.5017\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 51ms/step - loss: 7.8060 - accuracy: 0.5127\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 7.9710 - accuracy: 0.5011\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 10.4018 - accuracy: 0.0750: 0s - loss: 10.3773 - ac\n",
      "\n",
      " Epochs: 920 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 8.2955 - accuracy: 0.4817\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 8s 57ms/step - loss: 8.0214 - accuracy: 0.4980\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 9s 59ms/step - loss: 8.2496 - accuracy: 0.4817\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 9s 61ms/step - loss: 8.2975 - accuracy: 0.4817\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 8.1724 - accuracy: 0.4891\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 10.7260 - accuracy: 0.0746\n",
      "\n",
      " Epochs: 925 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 9s 60ms/step - loss: 8.2891 - accuracy: 0.4810\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 9s 61ms/step - loss: 8.2307 - accuracy: 0.4863\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 8.0594 - accuracy: 0.4961\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 8s 59ms/step - loss: 8.1880 - accuracy: 0.4880\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 8.0819 - accuracy: 0.4939\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 10.5864 - accuracy: 0.0790\n",
      "\n",
      " Epochs: 930 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 9s 60ms/step - loss: 8.0476 - accuracy: 0.4945\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 8s 59ms/step - loss: 8.2330 - accuracy: 0.4852\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 9s 62ms/step - loss: 8.0258 - accuracy: 0.4983\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 9s 61ms/step - loss: 7.8480 - accuracy: 0.5098 0s - loss: 7.8107 - accura\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 9s 62ms/step - loss: 7.9426 - accuracy: 0.5022\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 10.6272 - accuracy: 0.0761: 2s - loss: 10.9779 - accuracy: 0.08 - ETA: 2s - loss: 10.9960 - accuracy - ETA: 1s - loss: 10.8747 - accuracy: 0.07 - ETA: 1s - loss: 10.8542 - accuracy - ETA: 1s - loss: 10.748\n",
      "\n",
      " Epochs: 935 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 9s 62ms/step - loss: 8.1160 - accuracy: 0.4930\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 8s 59ms/step - loss: 8.3116 - accuracy: 0.4812\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 9s 60ms/step - loss: 8.0968 - accuracy: 0.4924\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 9s 62ms/step - loss: 8.2300 - accuracy: 0.4843\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 8.2423 - accuracy: 0.4852\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 10.6033 - accuracy: 0.0847: 2\n",
      "\n",
      " Epochs: 940 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 10s 66ms/step - loss: 8.1551 - accuracy: 0.4897\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 8.2027 - accuracy: 0.4873\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 8s 56ms/step - loss: 8.0584 - accuracy: 0.4950\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 9s 62ms/step - loss: 8.1755 - accuracy: 0.4871\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 8.1519 - accuracy: 0.4891\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 10.5569 - accuracy: 0.0788\n",
      "\n",
      " Epochs: 945 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 9s 60ms/step - loss: 8.1249 - accuracy: 0.4902\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 9s 59ms/step - loss: 8.1028 - accuracy: 0.4921 0s -\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 8s 56ms/step - loss: 8.1490 - accuracy: 0.4908\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 8.2932 - accuracy: 0.4825\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 59ms/step - loss: 7.9993 - accuracy: 0.4996\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 10.8236 - accuracy: 0.0850\n",
      "\n",
      " Epochs: 950 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 9s 60ms/step - loss: 7.8660 - accuracy: 0.5094\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 8.0611 - accuracy: 0.4954\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 8.1380 - accuracy: 0.4906\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 9s 65ms/step - loss: 8.2226 - accuracy: 0.4843\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 9s 60ms/step - loss: 8.1517 - accuracy: 0.4904\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 10.6094 - accuracy: 0.0763: 0s - loss: 10.5981 - ac\n",
      "\n",
      " Epochs: 955 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 9s 60ms/step - loss: 8.2811 - accuracy: 0.4832\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 8.2938 - accuracy: 0.4812\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 8s 55ms/step - loss: 7.8086 - accuracy: 0.5103\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 9s 61ms/step - loss: 8.4000 - accuracy: 0.4721\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 58ms/step - loss: 8.2350 - accuracy: 0.4823\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 10.6724 - accuracy: 0.0786\n",
      "\n",
      " Epochs: 960 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 9s 59ms/step - loss: 8.0610 - accuracy: 0.4941\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 9s 60ms/step - loss: 7.9523 - accuracy: 0.5024\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 8s 59ms/step - loss: 8.2586 - accuracy: 0.4834\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 10s 71ms/step - loss: 8.1627 - accuracy: 0.4895\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 7.9022 - accuracy: 0.5046\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 11.0656 - accuracy: 0.0759\n",
      "\n",
      " Epochs: 965 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 8.0138 - accuracy: 0.4989\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 9s 62ms/step - loss: 8.0227 - accuracy: 0.4991\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 9s 61ms/step - loss: 8.2099 - accuracy: 0.4873\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 9s 64ms/step - loss: 8.3094 - accuracy: 0.4823\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 9s 65ms/step - loss: 8.1211 - accuracy: 0.4919\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 10.3293 - accuracy: 0.0750: 3s - loss: 10.8 - ETA: 1s - loss: \n",
      "\n",
      " Epochs: 970 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 9s 66ms/step - loss: 8.1309 - accuracy: 0.4921\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 10s 72ms/step - loss: 8.2570 - accuracy: 0.4815\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 10s 69ms/step - loss: 8.1043 - accuracy: 0.4924\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 10s 70ms/step - loss: 8.0742 - accuracy: 0.4932\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 10s 72ms/step - loss: 8.0514 - accuracy: 0.4972\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 10.5291 - accuracy: 0.0801: 0s - loss: 10.5231 - ac\n",
      "\n",
      " Epochs: 975 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 10s 68ms/step - loss: 7.9574 - accuracy: 0.5028\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 7.9962 - accuracy: 0.5002\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 8.0579 - accuracy: 0.4952\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 7.8821 - accuracy: 0.5061\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 8.1282 - accuracy: 0.4908\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 10.8884 - accuracy: 0.0759\n",
      "\n",
      " Epochs: 980 \n",
      "\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 8.2603 - accuracy: 0.4832 0s - loss: 8.2\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 8s 54ms/step - loss: 8.1491 - accuracy: 0.4902\n",
      "Epoch 3/5\n",
      " 24/144 [====>.........................] - ETA: 6s - loss: 8.0266 - accuracy: 0.5000 ETA: 7s - l"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[32,128,88,1] and type uint8 on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[32,128,88,1] and type uint8 on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[sequential_2/conv2d_7/BiasAdd/ReadVariableOp/_40]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_93384]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-5972ae67c138>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mnew_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock_age_M_0_180\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Epochs: \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_acc\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-80350a489cb1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\tf20 gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\tf20 gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\tf20 gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\tf20 gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\tf20 gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\tf20 gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\tf20 gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[32,128,88,1] and type uint8 on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[32,128,88,1] and type uint8 on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[sequential_2/conv2d_7/BiasAdd/ReadVariableOp/_40]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_93384]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "acc = 0.0916\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(epochs<800):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_age_M_0_180)\n",
    "        b = \"Epochs: \"+ str(epochs)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_age_M_0_180.save(\"model_MVLP/MVLP_age_M_0_180.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "        print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 5s 8ms/step - loss: 4.5586 - accuracy: 0.0916\n"
     ]
    }
   ],
   "source": [
    "block_age_M_0_180 = tf.keras.models.load_model(\"model_MVLP/MVLP_age_M_0_180.h5\")\n",
    "test_loss, test_acc = block_age_M_0_180.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training age with Female_15_195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4767, 86)\n",
      "(4831, 86)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_female:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 15 or p.guessAngle == 195:\n",
    "        x_train.append(p.img)\n",
    "        y_train.append(p.age)\n",
    "        \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = to_cate(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_female:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 15 or p.guessAngle == 195:\n",
    "        x_test.append(p.img)\n",
    "        y_test.append(p.age)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = to_cate(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 86)                88150     \n",
      "=================================================================\n",
      "Total params: 23,334,941\n",
      "Trainable params: 23,334,815\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block_age_F_15_195 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "block_age_F_15_195.add(Dense(86, activation = 'softmax'))\n",
    "block_age_F_15_195.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "block_age_F_15_195.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "149/149 [==============================] - 4s 21ms/step - loss: 14.5699 - accuracy: 0.0335:\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 20ms/step - loss: 4.0030 - accuracy: 0.0548 0s - loss: 4.0089 - accu - ETA: 0s - loss: 4.0049 - accuracy: \n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 20ms/step - loss: 3.7609 - accuracy: 0.0829\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 20ms/step - loss: 3.6547 - accuracy: 0.0855\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 3.5713 - accuracy: 0.0948\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 3.7550 - accuracy: 0.0758\n",
      "\n",
      " Epochs: 5 Acc: 0.07576071470975876 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 3.5306 - accuracy: 0.0944\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 3.5114 - accuracy: 0.0969\n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 3.4306 - accuracy: 0.1137\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 3.3952 - accuracy: 0.1126 1s - loss: 3.3423 - accu - ETA: 0s - l\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 3.3231 - accuracy: 0.1254 2s - loss: 3.3122 - accuracy - ETA: 2s - loss: 3.3311 - accuracy:  - ETA: 2s - loss: 3.3158  - ETA: 1s - loss: 3.3011 - accuracy - ETA: 1s - loss: 3.3290 - accuracy:  - ETA: 1s - l - ETA: 0s - loss: 3.3272 - accuracy: 0.\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 3.7875 - accuracy: 0.0811\n",
      "\n",
      " Epochs: 10 Acc: 0.0811426192522049 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 3.2861 - accuracy: 0.1282 0s - loss: 3.2899 - accuracy - ETA: 0s - loss: 3.2916 - accuracy\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 3.1958 - accuracy: 0.1517 2s - loss: 3.1465 - accura - ETA: 1s - loss: 3.1817 -  - ETA: 1s - loss: 3.1945 - accu - ETA: 1s - loss: 3.1938 - accura - ETA: 0s - loss: 3.1831 - accuracy: 0.15 - ETA: 0s - loss: 3.1861  - ETA: 0s - loss: 3.1993 - accuracy: \n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 3.1447 - accuracy: 0.1607\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 4s 26ms/step - loss: 3.0731 - accuracy: 0.1745\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 2.9959 - accuracy: 0.1957 0s - loss:\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 4.2536 - accuracy: 0.0753: 0s - loss: 4.2617 - accuracy: 0.06 - ETA: 0s - loss: 4.2627 -  - ETA: 0s - loss: 4.2117 - ac\n",
      "\n",
      " Epochs: 15 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 2.8954 - accuracy: 0.2133 2s - - ETA: 1s - loss: 2.8624 - accuracy: 0.22 - ETA: 1s - los - ETA: 0s - loss: 2.8972 - accuracy - ETA: 0s - loss: 2.8988 - accuracy: \n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 2.8073 - accuracy: 0.2320 1s - loss: 2.7357 - accuracy: 0. - ETA: 1s - loss: 2.7347 - accuracy: 0. - ETA: 1s - loss: 2.7555 - accuracy:  - ETA: 1s - los - ETA: 0s - loss: 2.7983 - \n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 2.6920 - accuracy: 0.2547 2s - loss: 2 - ETA: 1s - loss: 2.6535 - accu - ETA: 1s - loss: 2.6642 -  - ETA: 1s - loss: 2 - ETA: 0s - loss: 2.6775 - accura\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 2.5719 - accuracy: 0.2851 0s - l\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 2.4702 - accuracy: 0.3113 1s - loss: 2.4632 - accuracy: 0.31 - ETA: 1s - loss: 2.4633 - accu - ETA: 1s - loss: 2.4690 - accura - ETA: 1s - loss: 2.4509 - accuracy: 0.32 - ETA: 1s - loss: 2.4550 - accuracy: 0. - ETA: 0s -\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 4.6715 - accuracy: 0.0741: 0s - loss: 4.716\n",
      "\n",
      " Epochs: 20 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 2.3596 - accuracy: 0.3327 0s - loss: 2.3442 - accuracy:  - ETA: 0s - loss: 2.3506 - accu - ETA: 0s - loss: 2.3575 - accuracy\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 2.2812 - accuracy: 0.3621 0s - loss: 2.2842 - \n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 2.1368 - accuracy: 0.3954 2s - loss: 2.0976  - ETA: 0s - loss: 2.111 - ETA: 0s - loss: 2.1340 - accuracy: 0.39\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 2.0263 - accuracy: 0.4154\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 4s 26ms/step - loss: 1.8692 - accuracy: 0.4605 0s - loss: 1.8488 - accura - ETA: 0s - loss: 1.8584 - accura\n",
      "151/151 [==============================] - 1s 8ms/step - loss: 5.6127 - accuracy: 0.0731\n",
      "\n",
      " Epochs: 25 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 1.7569 - accuracy: 0.4923 2s - ETA: 0s - loss: 1.7635 - accuracy: \n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 1.6085 - accuracy: 0.5173 0s - loss: 1.5837 \n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 1.5172 - accuracy: 0.5479 1s - loss: 1.474\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 1.3876 - accuracy: 0.5882 1s - loss: 1.345 - ETA: 0s - loss: 1.3908 - accu - ETA: 0s - loss: 1.3899 - accuracy\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 1.2557 - accuracy: 0.6209 1s - loss: 1.2383  - ETA: 1s - loss: 1.2455 -  - ETA: 0s - loss: 1.2506 - ac - ETA: 0s - loss: 1.2500 - accuracy: \n",
      "151/151 [==============================] - 1s 8ms/step - loss: 7.2116 - accuracy: 0.0658: 0s - loss: 7.1325 - accuracy: 0.\n",
      "\n",
      " Epochs: 30 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 1.1661 - accuracy: 0.6432 0s - loss: 1.1613 - accura\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 1.0854 - accuracy: 0.6702\n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 4s 26ms/step - loss: 0.9737 - accuracy: 0.7046\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.9213 - accuracy: 0.7147 0s - loss: 0.9237 \n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.8230 - accuracy: 0.7451 \n",
      "151/151 [==============================] - 1s 8ms/step - loss: 8.6973 - accuracy: 0.0662: 0s - loss: 8.6962 - ac\n",
      "\n",
      " Epochs: 35 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.8006 - accuracy: 0.7485 1s - loss: 0.7549 -  - ETA\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.7413 - accuracy: 0.7665 2s - loss: 0.6861 - accura - ETA: 1s - loss: 0.7162 - accuracy:  - - ETA: 0s - loss: 0.7472 - \n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.6036 - accuracy: 0.8110 0s - loss: 0.5871 - ac - ETA: 0s - loss: 0.5921 - accuracy - ETA: 0s - loss: 0.6033 - accuracy: 0.81\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.5688 - accuracy: 0.8227 1s - loss: 0.5737 - accuracy - ETA: 1s - loss: 0.5692 -  - ETA: 0s - los - ETA: 0s - loss: 0.5707 - accuracy: 0.\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.5780 - accuracy: 0.8215 1s - loss: 0.5406 - accu - ETA: 1s - l - ETA: 0s - loss: 0.5716 - accuracy\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 11.2134 - accuracy: 0.0696A: 0s - loss: 11.4818 - ac\n",
      "\n",
      " Epochs: 40 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.5557 - accuracy: 0.8244  - ETA: 0s - loss: 0.5476 - accuracy\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.5156 - accuracy: 0.8357- ETA: 1s - loss: 0.4770 - accuracy: 0.85 - ETA: 1s - loss: 0.4770 - accu - ETA: 1s - loss: 0.4 - ETA: 0s - loss: 0.5005 - \n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.5312 - accuracy: 0.8334 2s - loss: 0.5233 - accu - ETA: 2s - loss: 0.530 - ETA: 1s - loss: 0.5237 - accuracy: 0.83 - ETA: 1s - ETA: 0s - loss: 0.5124 - accuracy:  - ETA: 0s - loss: 0.5172 - accuracy - ETA: 0s - loss: 0.5290 - accuracy - ETA: 0s - loss: 0.5318 - accuracy: 0.83\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.4648 - accuracy: 0.8517 1s - loss: 0.4574 - accuracy:  - ETA: 0s - los\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.5077 - accuracy: 0.8464\n",
      "151/151 [==============================] - 1s 8ms/step - loss: 11.6715 - accuracy: 0.0677\n",
      "\n",
      " Epochs: 45 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.3858 - accuracy: 0.8808 2s - los\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 4s 27ms/step - loss: 0.3183 - accuracy: 0.9046\n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.2935 - accuracy: 0.9111 0s -\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.2784 - accuracy: 0.9207 1s - loss: 0.2978 - accuracy:  - ETA: 1s - loss: 0.2907 - accuracy: 0.91 - ETA: 1s - loss: - ETA: 0s - loss: 0.2786 - ac\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.2637 - accuracy: 0.9142 0s - loss: 0.2647 - accuracy: 0.91\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 14.3744 - accuracy: 0.0669A: 1s - loss: 14.676\n",
      "\n",
      " Epochs: 50 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.2732 - accuracy: 0.9157\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.3003 - accuracy: 0.9060 2s - los - ETA: 1s - - ETA: 0s - loss: 0.3\n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.4258 - accuracy: 0.8714 2s - loss: 0.3118 - accuracy - ETA: 2s - loss: - ETA: 1s - loss: 0.4264 - accu - ETA: 1s - loss: 0.4140 - accuracy: 0. - ETA: 1s - loss: 0.4067 - accuracy: 0. - ETA: 0s - loss: 0.410 - ETA: 0s - loss: 0.4241 - accura\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.5207 - accuracy: 0.8469\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.5138 - accuracy: 0.8588 1s - loss: 0.4492 - accu - ETA: 0s - loss: 0.4777 - accuracy: 0.86 - ETA: 0s - loss: 0.4750  - ETA: 0s - loss: 0.5046 - accuracy: \n",
      "151/151 [==============================] - ETA: 0s - loss: 12.5451 - accuracy: 0.056 - 1s 8ms/step - loss: 12.6353 - accuracy: 0.0559\n",
      "\n",
      " Epochs: 55 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.3672 - accuracy: 0.8819 0s - loss: 0.3527 - ac - ETA: 0s - loss: 0.3713 - accu\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.2467 - accuracy: 0.9236\n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1780 - accuracy: 0.9471 2s - loss: 0.2028 -  - ETA: 1s - loss: 0.198\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1310 - accuracy: 0.9616 2s - ETA: 1s - loss: 0.1256 - accuracy - ETA: 1s - loss: 0.1246 - accuracy: 0. - ETA: 0s - loss: 0.1246 - accuracy:  - ETA: 0s - loss:\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1165 - accuracy: 0.9692 2s - loss: 0.0905 - accuracy: 0. - ETA: 2s - loss: 0.0950 - accuracy: 0.97 - ETA: 2s - loss: 0.1114 - accuracy - ETA: 2s - ETA: 1s - loss: 0.1131 - accuracy:  - ETA\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 15.7689 - accuracy: 0.0673\n",
      "\n",
      " Epochs: 60 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1038 - accuracy: 0.9715\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.0973 - accuracy: 0.9742 2s - loss: 0.0799 - accuracy:  - ETA: 2s - loss: 0.0786 - accuracy: 0.98 - ETA: 1s - loss: 0.0823 - accuracy: 0.98 - ETA: 1s - loss: 0.0809 - accuracy: 0. - ETA: 1s - loss: 0.0788 - accuracy:  - ETA: 1s - loss: 0.0804 - accura - ETA: 1s - loss: 0.0817 -  - ETA: 0s - loss:\n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1280 - accuracy: 0.9610 2s - loss: 0.1439 - accuracy: 0.95 - ETA:  -\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 4s 26ms/step - loss: 0.1910 - accuracy: 0.9392 1s - los - ETA: 0s - loss: 0.1888 - accuracy: 0.\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.3469 - accuracy: 0.8976 2s - ETA: 1s - loss: 0.2 - ETA: 0s - loss: 0.2841 - accuracy:  - ETA: 0s - loss: 0.3018 - accuracy: 0.90 - ETA: 0s - loss: 0.3018 - accuracy: 0.90 - ETA: 0s - loss: 0.3017 - accuracy:  - ETA: 0s - loss: 0.3291 - accuracy: \n",
      "151/151 [==============================] - 1s 7ms/step - loss: 17.1389 - accuracy: 0.0660A: 0s - loss: 17.1105 - accur\n",
      "\n",
      " Epochs: 65 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.4452 - accuracy: 0.8720 0s - loss: 0.4422 - accura - ETA: 0s - loss: 0.4403 \n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.2856 - accuracy: 0.9144 2s - loss: 0.4283 - accuracy: 0. - E\n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 4s 25ms/step - loss: 0.1874 - accuracy: 0.9440\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 22ms/step - loss: 0.1506 - accuracy: 0.9534 0s - loss: 0.1614 - accu - ETA: 0s - loss: 0.1559 \n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1129 - accuracy: 0.9660 2s - loss: 0.0878 -  - ETA - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.1126 - accuracy: 0. - ETA: 0s - loss: 0.1135 - accuracy\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 17.1769 - accuracy: 0.0625\n",
      "\n",
      " Epochs: 70 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 4s 26ms/step - loss: 0.0972 - accuracy: 0.9704 2s - los\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 4s 26ms/step - loss: 0.1016 - accuracy: 0.9717\n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1281 - accuracy: 0.9578 1s - loss: 0 - ETA: 0s - loss:\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1413 - accuracy: 0.9566 1s - los - ETA: 0s - loss: 0.1364 - accuracy - ETA: 0s - loss: 0.1407 - accura\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1834 - accuracy: 0.9392 2s - loss: 0.1545 -  - ETA: 2s - loss: 0.1476 - ac - ETA: 1s - loss: 0.1759 - ac - ETA:  - ETA: 0s - loss: 0.1809 - accuracy:  - ETA: 0s - loss: 0.1807 - accuracy: \n",
      "151/151 [==============================] - 1s 7ms/step - loss: 19.1334 - accuracy: 0.0664\n",
      "\n",
      " Epochs: 75 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1827 - accuracy: 0.9438 1s - loss: - ETA: 0s - loss: 0.1740 - accuracy - ETA: 0s - loss: 0\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.2136 - accuracy: 0.9366 1s - loss: 0.1949  - ETA: 1s - loss: 0.1 - ETA: 0s - loss: 0.2\n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.2297 - accuracy: 0.9280 2s - - ETA: 1s - loss: 0.1879 - accura - ETA: 1s - loss: 0.1913 - accuracy: 0. - ETA: 0s - l\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.2204 - accuracy: 0.9343 2s - loss: 0.2327 - accuracy: 0.94 - ETA: 2s - loss: 0.2167 - accuracy - ETA: 2s - loss: 0 - ETA: 1s - loss: 0.224 - ETA: 1s\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1912 - accuracy: 0.9406 2s - loss: 0 - ETA: 1s - loss: 0.2133 - accu - ETA: 1s - los - ETA: 0s - loss: 0.2018 - accu - ETA: 0s - loss: 0.1947 - accuracy\n",
      "151/151 [==============================] - 1s 8ms/step - loss: 17.8257 - accuracy: 0.0609\n",
      "\n",
      " Epochs: 80 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1403 - accuracy: 0.9553 2s - loss: 0.1440 - accuracy:  - ETA: 2s - loss: 0.1\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.0832 - accuracy: 0.9738 1s - loss: 0.0867 - accuracy:  - ETA: 1s - loss: 0.0829 - accu\n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.0542 - accuracy: 0.9843 2s - loss: 0.0658 - accuracy: 0. - E - ETA: 1s - loss: 0.0553 - accuracy:  - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.0563 - accu\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.0444 - accuracy: 0.9880 2s - loss: 0.0526 - accura - ETA: 2s - loss: 0.0 - ETA: 1s - loss: 0.0520 - ac\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.0446 - accuracy: 0.9870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 1s 7ms/step - loss: 19.5633 - accuracy: 0.0646A: 0s - loss: 20.1243 \n",
      "\n",
      " Epochs: 85 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 22ms/step - loss: 0.0354 - accuracy: 0.9912 0s - loss: 0.0356 - accuracy\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 22ms/step - loss: 0.0396 - accuracy: 0.9906 2s - loss: 0.0405 - accu - ETA\n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 4s 24ms/step - loss: 0.0657 - accuracy: 0.9807\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1847 - accuracy: 0.9492 0s - loss: 0.1834 - accura\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 4s 27ms/step - loss: 0.3693 - accuracy: 0.9039 2s -\n",
      "151/151 [==============================] - 1s 8ms/step - loss: 19.6629 - accuracy: 0.0596\n",
      "\n",
      " Epochs: 90 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.2948 - accuracy: 0.9188 0s - loss:\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1253 - accuracy: 0.9635 1s - loss: 0.1265 - accuracy: 0. - ETA: 0s - loss: 0.1246 - accuracy:  - ETA: 0s - loss:\n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.0835 - accuracy: 0.9740 2s - loss: 0.0697 -  - ETA: 2s - loss: 0\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.1095 - accuracy: 0.9687 2s - loss: 0.1355 - accuracy:  - E - ETA: 1s - loss: 0.1074 -  - ETA: 0s - loss: 0.112\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.0748 - accuracy: 0.9763 2s - l - ETA: 1s - loss: 0.0854 - accuracy: 0.97 - ETA: 0s - loss: 0.0781 - accura - ETA: 0s - loss: 0.0751 - accuracy: 0.97\n",
      "151/151 [==============================] - 1s 8ms/step - loss: 20.2112 - accuracy: 0.0563\n",
      "\n",
      " Epochs: 95 \n",
      "\n",
      "Epoch 1/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.0345 - accuracy: 0.9876 2s - loss: 0.0333 - accu - ETA: 2s - loss: 0.0333 - ac - ETA: 1s - loss: 0.0350  - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.0318 - ac - ETA: 0s - loss: 0.0348 - accuracy: 0.\n",
      "Epoch 2/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.0207 - accuracy: 0.9941\n",
      "Epoch 3/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.0197 - accuracy: 0.9950 2s - loss: 0.0130 - accuracy: 0. - ETA: 2s - loss: 0.0111 - accuracy - ETA: 2s - loss: 0.0 - ETA: 1s - loss: 0.0195 - ac - ETA: 1s - loss: 0.0179 - accuracy: 0. - ETA: 1s - loss: 0.0172 -  - ETA: 0s - loss: 0.0196 - accuracy: 0. - ETA: 0s - loss: 0.019\n",
      "Epoch 4/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.0162 - accuracy: 0.9956 2s - loss: 0.0 - ETA: 1s - loss: 0.0179  - ETA: 1s - los - ETA: 0s - loss: 0.0169 - accuracy - ETA: 0s - loss: 0.0162 - accuracy: 0.99\n",
      "Epoch 5/5\n",
      "149/149 [==============================] - 3s 21ms/step - loss: 0.0129 - accuracy: 0.9973 0s - loss: 0.0145 \n",
      "151/151 [==============================] - 1s 8ms/step - loss: 21.7949 - accuracy: 0.0627\n",
      "\n",
      " Epochs: 100 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0.0811\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(epochs<100):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_age_F_15_195)\n",
    "        b = \"Epochs: \"+ str(epochs)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_age_F_15_195.save(\"model_MVLP/MVLP_age_F_15_195.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "        print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 1s 7ms/step - loss: 3.7875 - accuracy: 0.0811\n"
     ]
    }
   ],
   "source": [
    "block_age_F_15_195 = tf.keras.models.load_model(\"model_MVLP/MVLP_age_F_15_195.h5\")\n",
    "test_loss, test_acc = block_age_F_15_195.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training age with Male_15_195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4727, 86)\n",
      "(4663, 86)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_male:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 15 or p.guessAngle == 195:\n",
    "        x_train.append(p.img)\n",
    "        y_train.append(p.age)\n",
    "        \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = to_cate(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_male:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 15 or p.guessAngle == 195:\n",
    "        x_test.append(p.img)\n",
    "        y_test.append(p.age)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = to_cate(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 86)                88150     \n",
      "=================================================================\n",
      "Total params: 23,334,941\n",
      "Trainable params: 23,334,815\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block_age_M_15_195 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "block_age_M_15_195.add(Dense(86, activation = 'softmax'))\n",
    "block_age_M_15_195.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "block_age_M_15_195.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0.0843\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(epochs<100):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_age_M_15_195)\n",
    "        b = \"Epochs: \"+ str(epochs)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_age_M_15_195.save(\"model_MVLP/MVLP_age_M_15_195.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "        print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 1s 8ms/step - loss: 3.8192 - accuracy: 0.0843\n"
     ]
    }
   ],
   "source": [
    "block_age_M_15_195 = tf.keras.models.load_model(\"model_MVLP/MVLP_age_M_15_195.h5\")\n",
    "test_loss, test_acc = block_age_M_15_195.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training age with Female_30_45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4914, 86)\n",
      "(4999, 86)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_female:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 30 or p.guessAngle == 45:\n",
    "        x_train.append(p.img)\n",
    "        y_train.append(p.age)\n",
    "        \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = to_cate(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_female:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 30 or p.guessAngle == 45:\n",
    "        x_test.append(p.img)\n",
    "        y_test.append(p.age)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = to_cate(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 86)                88150     \n",
      "=================================================================\n",
      "Total params: 23,334,941\n",
      "Trainable params: 23,334,815\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    block_age_F_30_45 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "    block_age_F_30_45.add(Dense(86, activation = 'softmax'))\n",
    "    block_age_F_30_45.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "    block_age_F_30_45.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0.0790\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(epochs<50):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_age_F_30_45)\n",
    "        b = \"Epochs: \"+ str(epochs)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_age_F_30_45.save(\"model_MVLP/MVLP_age_F_30_45.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "        print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 8ms/step - loss: 3.8313 - accuracy: 0.0848\n"
     ]
    }
   ],
   "source": [
    "block_age_F_30_45 = tf.keras.models.load_model(\"model_MVLP/MVLP_age_F_30_45.h5\")\n",
    "test_loss, test_acc = block_age_F_30_45.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training age with Male_30_45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4912, 86)\n",
      "(4826, 86)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_male:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 30 or p.guessAngle == 45:\n",
    "        x_train.append(p.img)\n",
    "        y_train.append(p.age)\n",
    "        \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = to_cate(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_male:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 30 or p.guessAngle == 45:\n",
    "        x_test.append(p.img)\n",
    "        y_test.append(p.age)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = to_cate(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 86)                88150     \n",
      "=================================================================\n",
      "Total params: 23,334,941\n",
      "Trainable params: 23,334,815\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    block_age_M_30_45 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "    block_age_M_30_45.add(Dense(86, activation = 'softmax'))\n",
    "    block_age_M_30_45.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "    block_age_M_30_45.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(epochs<50):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_age_M_30_45)\n",
    "        b = \"Epochs: \"+ str(epochs)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_age_M_30_45.save(\"model_MVLP/MVLP_age_M_30_45.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "        print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 1s 8ms/step - loss: 3.8162 - accuracy: 0.0901\n"
     ]
    }
   ],
   "source": [
    "block_age_M_30_45 = tf.keras.models.load_model(\"model_MVLP/MVLP_age_M_30_45.h5\")\n",
    "test_loss, test_acc = block_age_M_30_45.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training age with Female_60_75_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7240, 86)\n",
      "(7335, 86)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_female:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 60 or p.guessAngle == 75 or p.guessAngle == 90:\n",
    "        x_train.append(p.img)\n",
    "        y_train.append(p.age)\n",
    "        \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = to_cate(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_female:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 60 or p.guessAngle == 75 or p.guessAngle == 90:\n",
    "        x_test.append(p.img)\n",
    "        y_test.append(p.age)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = to_cate(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 86)                88150     \n",
      "=================================================================\n",
      "Total params: 23,334,941\n",
      "Trainable params: 23,334,815\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    block_age_F_60_75_90 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "    block_age_F_60_75_90.add(Dense(86, activation = 'softmax'))\n",
    "    block_age_F_60_75_90.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "    block_age_F_60_75_90.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "227/227 [==============================] - 25s 108ms/step - loss: 11.5441 - accuracy: 0.0425\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 25s 109ms/step - loss: 3.6531 - accuracy: 0.0936\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 24s 106ms/step - loss: 3.4718 - accuracy: 0.1054\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 24s 104ms/step - loss: 3.3832 - accuracy: 0.1154\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 24s 105ms/step - loss: 3.2098 - accuracy: 0.1451\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 3.6514 - accuracy: 0.0852\n",
      "\n",
      " Epochs: 5 Acc: 0.08520790934562683 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 26s 113ms/step - loss: 3.1333 - accuracy: 0.1579\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 25s 109ms/step - loss: 3.0134 - accuracy: 0.1849\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 24s 107ms/step - loss: 2.9162 - accuracy: 0.2048\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 25s 108ms/step - loss: 2.7906 - accuracy: 0.2297\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 25s 108ms/step - loss: 2.6640 - accuracy: 0.2533\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 4.3437 - accuracy: 0.0785\n",
      "\n",
      " Epochs: 10 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 25s 109ms/step - loss: 2.5401 - accuracy: 0.2906\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 25s 111ms/step - loss: 2.3504 - accuracy: 0.3377\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 25s 110ms/step - loss: 2.1638 - accuracy: 0.3870\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 25s 109ms/step - loss: 1.9867 - accuracy: 0.4294\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 25s 111ms/step - loss: 1.7555 - accuracy: 0.4949\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 5.8735 - accuracy: 0.0676- ETA: 0s - loss: 5.7943 - accura\n",
      "\n",
      " Epochs: 15 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 24s 105ms/step - loss: 1.5451 - accuracy: 0.5506\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 23s 102ms/step - loss: 1.3559 - accuracy: 0.6026\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 23s 103ms/step - loss: 1.1615 - accuracy: 0.6550\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 24s 104ms/step - loss: 0.9722 - accuracy: 0.7076\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 23s 103ms/step - loss: 0.8110 - accuracy: 0.7517\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 8.2872 - accuracy: 0.0718\n",
      "\n",
      " Epochs: 20 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 24s 106ms/step - loss: 0.6938 - accuracy: 0.7865\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 23s 102ms/step - loss: 0.5640 - accuracy: 0.8242\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 23s 101ms/step - loss: 0.4939 - accuracy: 0.8465\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 23s 101ms/step - loss: 0.3922 - accuracy: 0.8785\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 23s 102ms/step - loss: 0.3819 - accuracy: 0.8826\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 10.4078 - accuracy: 0.0643: 1s - loss: 10 - ETA: 0s - loss: 10.3679 - accuracy: 0.0\n",
      "\n",
      " Epochs: 25 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 23s 103ms/step - loss: 0.3844 - accuracy: 0.8800\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 23s 103ms/step - loss: 0.3174 - accuracy: 0.8992\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 23s 102ms/step - loss: 0.2413 - accuracy: 0.9250\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 26s 115ms/step - loss: 0.2445 - accuracy: 0.9210\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 28s 125ms/step - loss: 0.1354 - accuracy: 0.9565\n",
      "230/230 [==============================] - 5s 20ms/step - loss: 13.1971 - accuracy: 0.0668: 3s - loss: 13.3574 - accur\n",
      "\n",
      " Epochs: 30 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 28s 125ms/step - loss: 0.1157 - accuracy: 0.9640\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 28s 124ms/step - loss: 0.1546 - accuracy: 0.9532\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 26s 116ms/step - loss: 0.2682 - accuracy: 0.9204\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 25s 111ms/step - loss: 0.3085 - accuracy: 0.9088\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 25s 112ms/step - loss: 0.1504 - accuracy: 0.9526\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 14.4909 - accuracy: 0.0648\n",
      "\n",
      " Epochs: 35 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 25s 110ms/step - loss: 0.1334 - accuracy: 0.9588\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 25s 110ms/step - loss: 0.0996 - accuracy: 0.9669\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 27s 120ms/step - loss: 0.0815 - accuracy: 0.9738\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 31s 136ms/step - loss: 0.1099 - accuracy: 0.9673\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 25s 111ms/step - loss: 0.1172 - accuracy: 0.9644\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 16.2886 - accuracy: 0.0678\n",
      "\n",
      " Epochs: 40 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 26s 112ms/step - loss: 0.0876 - accuracy: 0.9732\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 27s 121ms/step - loss: 0.1412 - accuracy: 0.9588\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 25s 112ms/step - loss: 0.1664 - accuracy: 0.9546\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 25s 111ms/step - loss: 0.1781 - accuracy: 0.9454\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 25s 112ms/step - loss: 0.1002 - accuracy: 0.9686\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 17.6798 - accuracy: 0.0660: 0s - loss: 17.4274 - accurac\n",
      "\n",
      " Epochs: 45 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 25s 108ms/step - loss: 0.0683 - accuracy: 0.9783\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 26s 115ms/step - loss: 0.0724 - accuracy: 0.9797\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 27s 120ms/step - loss: 0.0809 - accuracy: 0.9757\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 25s 112ms/step - loss: 0.0838 - accuracy: 0.9751\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 25s 110ms/step - loss: 0.0869 - accuracy: 0.9744\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 18.4253 - accuracy: 0.0705\n",
      "\n",
      " Epochs: 50 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(epochs<50):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_age_F_60_75_90)\n",
    "        b = \"Epochs: \"+ str(epochs)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_age_F_60_75_90.save(\"model_MVLP/MVLP_age_F_60_75_90.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "        print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 2s 8ms/step - loss: 3.6514 - accuracy: 0.0852\n"
     ]
    }
   ],
   "source": [
    "block_age_F_60_75_90 = tf.keras.models.load_model(\"model_MVLP/MVLP_age_F_60_75_90.h5\")\n",
    "test_loss, test_acc = block_age_F_60_75_90.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training age with Male_60_75_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7282, 86)\n",
      "(7220, 86)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_male:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 60 or p.guessAngle == 75 or p.guessAngle == 90:\n",
    "        x_train.append(p.img)\n",
    "        y_train.append(p.age)\n",
    "        \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = to_cate(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_male:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 60 or p.guessAngle == 75 or p.guessAngle == 90:\n",
    "        x_test.append(p.img)\n",
    "        y_test.append(p.age)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = to_cate(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 86)                88150     \n",
      "=================================================================\n",
      "Total params: 23,334,941\n",
      "Trainable params: 23,334,815\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    block_age_M_60_75_90 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "    block_age_M_60_75_90.add(Dense(86, activation = 'softmax'))\n",
    "    block_age_M_60_75_90.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "    block_age_M_60_75_90.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "228/228 [==============================] - 28s 119ms/step - loss: 11.7526 - accuracy: 0.0371\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 28s 124ms/step - loss: 3.6136 - accuracy: 0.0802\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 28s 123ms/step - loss: 3.4540 - accuracy: 0.1107\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 26s 115ms/step - loss: 3.3837 - accuracy: 0.1071\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 26s 114ms/step - loss: 3.2668 - accuracy: 0.1267\n",
      "226/226 [==============================] - 4s 18ms/step - loss: 3.8547 - accuracy: 0.0688\n",
      "\n",
      " Epochs: 5 Acc: 0.06883656233549118 \n",
      "\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 29s 125ms/step - loss: 3.1737 - accuracy: 0.1399\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 28s 125ms/step - loss: 3.0752 - accuracy: 0.1560\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 27s 117ms/step - loss: 2.9715 - accuracy: 0.1752\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 25s 108ms/step - loss: 2.8665 - accuracy: 0.2031\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 26s 113ms/step - loss: 2.7677 - accuracy: 0.2238\n",
      "226/226 [==============================] - 3s 15ms/step - loss: 3.8971 - accuracy: 0.0864 2s - ETA: 1s - loss: 3.778 - ETA: 0s - loss: 3.7778 - ac\n",
      "\n",
      " Epochs: 10 Acc: 0.08642659336328506 \n",
      "\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 28s 122ms/step - loss: 2.6590 - accuracy: 0.2475\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 29s 126ms/step - loss: 2.5145 - accuracy: 0.2865\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 28s 124ms/step - loss: 2.3951 - accuracy: 0.3171\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 29s 128ms/step - loss: 2.2273 - accuracy: 0.3609\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 29s 126ms/step - loss: 2.0764 - accuracy: 0.3960\n",
      "226/226 [==============================] - 4s 17ms/step - loss: 4.8616 - accuracy: 0.0868 1s - loss: 4.7174 - accuracy: 0.08 - E\n",
      "\n",
      " Epochs: 15 Acc: 0.08684210479259491 \n",
      "\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 29s 129ms/step - loss: 1.8923 - accuracy: 0.4475\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 29s 126ms/step - loss: 1.7305 - accuracy: 0.4864\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 29s 128ms/step - loss: 1.5703 - accuracy: 0.5328\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 29s 127ms/step - loss: 1.3919 - accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 29s 126ms/step - loss: 1.2545 - accuracy: 0.6184\n",
      "226/226 [==============================] - 4s 18ms/step - loss: 6.4177 - accuracy: 0.0760\n",
      "\n",
      " Epochs: 20 \n",
      "\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 29s 127ms/step - loss: 1.1240 - accuracy: 0.6561\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 29s 127ms/step - loss: 0.9916 - accuracy: 0.6961\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 29s 126ms/step - loss: 0.8994 - accuracy: 0.7203\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 29s 127ms/step - loss: 0.8027 - accuracy: 0.7439\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 29s 128ms/step - loss: 0.6646 - accuracy: 0.7903\n",
      "226/226 [==============================] - 4s 18ms/step - loss: 8.9441 - accuracy: 0.0827\n",
      "\n",
      " Epochs: 25 \n",
      "\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 29s 128ms/step - loss: 0.5929 - accuracy: 0.8156\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 26s 114ms/step - loss: 0.6026 - accuracy: 0.8091\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 26s 113ms/step - loss: 0.5407 - accuracy: 0.8285\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 26s 113ms/step - loss: 0.4601 - accuracy: 0.8503\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 25s 112ms/step - loss: 0.3792 - accuracy: 0.8783\n",
      "226/226 [==============================] - 4s 16ms/step - loss: 10.8213 - accuracy: 0.0796: 2s - loss: 10.2673 -  - ETA: 1s - loss: \n",
      "\n",
      " Epochs: 30 \n",
      "\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 26s 112ms/step - loss: 0.3588 - accuracy: 0.8901\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 26s 112ms/step - loss: 0.3268 - accuracy: 0.8971\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 25s 111ms/step - loss: 0.3341 - accuracy: 0.8926\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 26s 112ms/step - loss: 0.3585 - accuracy: 0.8849\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 25s 111ms/step - loss: 0.2731 - accuracy: 0.9143\n",
      "226/226 [==============================] - 4s 16ms/step - loss: 13.6871 - accuracy: 0.0762\n",
      "\n",
      " Epochs: 35 \n",
      "\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 26s 112ms/step - loss: 0.2254 - accuracy: 0.9300\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 26s 112ms/step - loss: 0.2091 - accuracy: 0.9341\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 25s 112ms/step - loss: 0.1891 - accuracy: 0.9420\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 26s 112ms/step - loss: 0.1977 - accuracy: 0.9366\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 26s 112ms/step - loss: 0.2877 - accuracy: 0.9132\n",
      "226/226 [==============================] - 3s 15ms/step - loss: 13.6220 - accuracy: 0.0807\n",
      "\n",
      " Epochs: 40 \n",
      "\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 26s 113ms/step - loss: 0.2270 - accuracy: 0.9296\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 26s 116ms/step - loss: 0.2032 - accuracy: 0.9349\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 26s 114ms/step - loss: 0.1995 - accuracy: 0.9425\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 26s 112ms/step - loss: 0.1523 - accuracy: 0.9539\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 25s 112ms/step - loss: 0.1408 - accuracy: 0.9562\n",
      "226/226 [==============================] - 3s 15ms/step - loss: 15.9870 - accuracy: 0.0720\n",
      "\n",
      " Epochs: 45 \n",
      "\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 26s 112ms/step - loss: 0.1773 - accuracy: 0.9418\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 25s 111ms/step - loss: 0.1976 - accuracy: 0.9390\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 26s 113ms/step - loss: 0.1641 - accuracy: 0.9488\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 26s 113ms/step - loss: 0.1315 - accuracy: 0.9600\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 26s 113ms/step - loss: 0.1207 - accuracy: 0.9633\n",
      "226/226 [==============================] - 3s 15ms/step - loss: 16.1967 - accuracy: 0.0824: 3s - loss: 14. - ETA: 1s - loss\n",
      "\n",
      " Epochs: 50 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(epochs<50):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_age_M_60_75_90)\n",
    "        b = \"Epochs: \"+ str(epochs)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_age_M_60_75_90.save(\"model_MVLP/MVLP_age_M_60_75_90.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "        print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 2s 8ms/step - loss: 4.8616 - accuracy: 0.0868\n"
     ]
    }
   ],
   "source": [
    "block_age_M_60_75_90 = tf.keras.models.load_model(\"model_MVLP/MVLP_age_M_60_75_90.h5\")\n",
    "test_loss, test_acc = block_age_M_60_75_90.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training age with Female_210_225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4936, 86)\n",
      "(5017, 86)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_female:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 210 or p.guessAngle == 225:\n",
    "        x_train.append(p.img)\n",
    "        y_train.append(p.age)\n",
    "        \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = to_cate(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_female:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 210 or p.guessAngle == 225:\n",
    "        x_test.append(p.img)\n",
    "        y_test.append(p.age)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = to_cate(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 86)                88150     \n",
      "=================================================================\n",
      "Total params: 23,334,941\n",
      "Trainable params: 23,334,815\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    block_age_F_210_225 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "    block_age_F_210_225.add(Dense(86, activation = 'softmax'))\n",
    "    block_age_F_210_225.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "    block_age_F_210_225.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "155/155 [==============================] - 17s 109ms/step - loss: 14.7830 - accuracy: 0.0391\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 20s 128ms/step - loss: 3.8437 - accuracy: 0.0644\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 20s 127ms/step - loss: 3.6227 - accuracy: 0.0851\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 20s 131ms/step - loss: 3.5313 - accuracy: 0.0915\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 19s 121ms/step - loss: 3.4822 - accuracy: 0.1056\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 3.8358 - accuracy: 0.0775\n",
      "\n",
      " Epochs: 5 Acc: 0.07753637433052063 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 18s 119ms/step - loss: 3.4090 - accuracy: 0.1114\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 17s 113ms/step - loss: 3.3535 - accuracy: 0.1124\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 18s 118ms/step - loss: 3.2993 - accuracy: 0.1187\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 17s 111ms/step - loss: 3.2367 - accuracy: 0.1309\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 17s 109ms/step - loss: 3.1811 - accuracy: 0.1376\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 3.6775 - accuracy: 0.0777\n",
      "\n",
      " Epochs: 10 Acc: 0.07773569971323013 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 17s 110ms/step - loss: 3.1143 - accuracy: 0.1564\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 16s 106ms/step - loss: 3.0770 - accuracy: 0.1661\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 16s 105ms/step - loss: 3.0028 - accuracy: 0.1742\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 16s 105ms/step - loss: 2.9615 - accuracy: 0.1831\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 16s 100ms/step - loss: 2.8690 - accuracy: 0.2018\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 3.9697 - accuracy: 0.0859 2s - loss: 3.9297 -  - ETA: 1s - loss: 3.9753 - accuracy: 0. - ETA: 1s - loss: 3.9 - ETA: 0s - loss: 3\n",
      "\n",
      " Epochs: 15 Acc: 0.08590791374444962 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 16s 100ms/step - loss: 2.7839 - accuracy: 0.2172\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 16s 101ms/step - loss: 2.6889 - accuracy: 0.2435\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 16s 101ms/step - loss: 2.5866 - accuracy: 0.2682\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 16s 102ms/step - loss: 2.4803 - accuracy: 0.2895\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 16s 102ms/step - loss: 2.3546 - accuracy: 0.3235\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 4.4656 - accuracy: 0.0666\n",
      "\n",
      " Epochs: 20 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 16s 101ms/step - loss: 2.2524 - accuracy: 0.3525\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 17s 107ms/step - loss: 2.1069 - accuracy: 0.3944\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 17s 111ms/step - loss: 1.9845 - accuracy: 0.4157\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 16s 102ms/step - loss: 1.8651 - accuracy: 0.4502\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 16s 102ms/step - loss: 1.7199 - accuracy: 0.4921\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 5.9548 - accuracy: 0.0674\n",
      "\n",
      " Epochs: 25 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 16s 100ms/step - loss: 1.5451 - accuracy: 0.5407\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 17s 110ms/step - loss: 1.4018 - accuracy: 0.5827\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 16s 103ms/step - loss: 1.3066 - accuracy: 0.6060\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 20s 130ms/step - loss: 1.1750 - accuracy: 0.6414\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 18s 114ms/step - loss: 1.0267 - accuracy: 0.6840\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 7.8111 - accuracy: 0.0666\n",
      "\n",
      " Epochs: 30 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 16s 104ms/step - loss: 0.9655 - accuracy: 0.7020\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 16s 102ms/step - loss: 0.8216 - accuracy: 0.7462\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 16s 103ms/step - loss: 0.7290 - accuracy: 0.7774\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 19s 120ms/step - loss: 0.6538 - accuracy: 0.8011\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 17s 109ms/step - loss: 0.5937 - accuracy: 0.8215\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 9.9254 - accuracy: 0.0658\n",
      "\n",
      " Epochs: 35 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 17s 107ms/step - loss: 0.5498 - accuracy: 0.8312\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 16s 106ms/step - loss: 0.5213 - accuracy: 0.8418\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 17s 110ms/step - loss: 0.4331 - accuracy: 0.8703\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 17s 109ms/step - loss: 0.4145 - accuracy: 0.8736\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 18s 114ms/step - loss: 0.4290 - accuracy: 0.8714\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 11.4610 - accuracy: 0.0732\n",
      "\n",
      " Epochs: 40 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 18s 113ms/step - loss: 0.3617 - accuracy: 0.8855\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 18s 114ms/step - loss: 0.3513 - accuracy: 0.8936\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 17s 113ms/step - loss: 0.3457 - accuracy: 0.8957\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 17s 111ms/step - loss: 0.2985 - accuracy: 0.9088\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 17s 113ms/step - loss: 0.2498 - accuracy: 0.9252\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 12.8312 - accuracy: 0.0658\n",
      "\n",
      " Epochs: 45 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 18s 115ms/step - loss: 0.2784 - accuracy: 0.9161\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 18s 113ms/step - loss: 0.2585 - accuracy: 0.9240\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 18s 115ms/step - loss: 0.1987 - accuracy: 0.9390\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 18s 115ms/step - loss: 0.1739 - accuracy: 0.9487\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 17s 109ms/step - loss: 0.1362 - accuracy: 0.9589\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 14.3630 - accuracy: 0.0616: 1s - loss: 14.342 - ETA: 0s - loss: 14.2085 - accuracy: 0.063 - ETA: 0s - loss: 14.2095 - accuracy: 0.0\n",
      "\n",
      " Epochs: 50 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(epochs<50):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_age_F_210_225)\n",
    "        b = \"Epochs: \"+ str(epochs)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_age_F_210_225.save(\"model_MVLP/MVLP_age_F_210_225.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "        print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 7ms/step - loss: 3.9697 - accuracy: 0.0859\n"
     ]
    }
   ],
   "source": [
    "block_age_F_210_225 = tf.keras.models.load_model(\"model_MVLP/MVLP_age_F_210_225.h5\")\n",
    "test_loss, test_acc = block_age_F_210_225.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training age with Male_210_225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4937, 86)\n",
      "(4865, 86)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_male:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 210 or p.guessAngle == 225:\n",
    "        x_train.append(p.img)\n",
    "        y_train.append(p.age)\n",
    "        \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = to_cate(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_male:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 210 or p.guessAngle == 225:\n",
    "        x_test.append(p.img)\n",
    "        y_test.append(p.age)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = to_cate(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 86)                88150     \n",
      "=================================================================\n",
      "Total params: 23,334,941\n",
      "Trainable params: 23,334,815\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    block_age_M_210_225 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "    block_age_M_210_225.add(Dense(86, activation = 'softmax'))\n",
    "    block_age_M_210_225.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "    block_age_M_210_225.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "155/155 [==============================] - 16s 102ms/step - loss: 16.9128 - accuracy: 0.0410\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 16s 102ms/step - loss: 3.6953 - accuracy: 0.0688\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 16s 103ms/step - loss: 3.5656 - accuracy: 0.0894\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 16s 103ms/step - loss: 3.4355 - accuracy: 0.1193\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 16s 106ms/step - loss: 3.3354 - accuracy: 0.1177\n",
      "153/153 [==============================] - 3s 17ms/step - loss: 3.6945 - accuracy: 0.0828\n",
      "\n",
      " Epochs: 5 Acc: 0.0828365907073021 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 16s 104ms/step - loss: 3.2739 - accuracy: 0.1298\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 16s 103ms/step - loss: 3.2176 - accuracy: 0.1373\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 16s 102ms/step - loss: 3.1484 - accuracy: 0.1525\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 16s 104ms/step - loss: 3.0670 - accuracy: 0.1665\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 16s 102ms/step - loss: 2.9815 - accuracy: 0.1906\n",
      "153/153 [==============================] - 3s 16ms/step - loss: 3.7900 - accuracy: 0.0855\n",
      "\n",
      " Epochs: 10 Acc: 0.08550873398780823 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 16s 104ms/step - loss: 2.8974 - accuracy: 0.2080\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 17s 108ms/step - loss: 2.7979 - accuracy: 0.2263\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 16s 106ms/step - loss: 2.6637 - accuracy: 0.2639\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 16s 105ms/step - loss: 2.5607 - accuracy: 0.2751\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 17s 107ms/step - loss: 2.4592 - accuracy: 0.3052\n",
      "153/153 [==============================] - 3s 18ms/step - loss: 4.0272 - accuracy: 0.0855\n",
      "\n",
      " Epochs: 15 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 17s 108ms/step - loss: 2.3250 - accuracy: 0.3354\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 17s 107ms/step - loss: 2.1791 - accuracy: 0.3737\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 17s 107ms/step - loss: 2.0202 - accuracy: 0.4102\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 16s 104ms/step - loss: 1.8304 - accuracy: 0.4750\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 16s 105ms/step - loss: 1.6735 - accuracy: 0.5080\n",
      "153/153 [==============================] - 3s 17ms/step - loss: 5.3515 - accuracy: 0.0867 0s - loss: 5\n",
      "\n",
      " Epochs: 20 Acc: 0.08674203604459763 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 16s 100ms/step - loss: 1.4941 - accuracy: 0.5522\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 1.3131 - accuracy: 0.6103\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 15s 99ms/step - loss: 1.2030 - accuracy: 0.6358\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.9728 - accuracy: 0.7081\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.7745 - accuracy: 0.7663\n",
      "153/153 [==============================] - 2s 16ms/step - loss: 7.4368 - accuracy: 0.0832 0s - loss: 7.258\n",
      "\n",
      " Epochs: 25 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.7348 - accuracy: 0.7648\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 15s 99ms/step - loss: 0.6376 - accuracy: 0.8005\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.5040 - accuracy: 0.8442\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.3689 - accuracy: 0.8843\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.2976 - accuracy: 0.9131\n",
      "153/153 [==============================] - 2s 16ms/step - loss: 9.7298 - accuracy: 0.0849 1s - loss: 9.7772 - accuracy: 0. - ETA: 1s - loss: 9.6 - ETA: 0s - loss: 9\n",
      "\n",
      " Epochs: 30 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 15s 99ms/step - loss: 0.2262 - accuracy: 0.9330\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.2445 - accuracy: 0.9251\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.3956 - accuracy: 0.8805\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.3617 - accuracy: 0.8866\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.2759 - accuracy: 0.9115\n",
      "153/153 [==============================] - 2s 16ms/step - loss: 11.4021 - accuracy: 0.0820: 1s - loss: 11.3285 - accurac - ETA: 0s - loss: 11.1416 - accuracy\n",
      "\n",
      " Epochs: 35 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 15s 99ms/step - loss: 0.1583 - accuracy: 0.9492\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 15s 100ms/step - loss: 0.1494 - accuracy: 0.9508\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.1141 - accuracy: 0.9668\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.1119 - accuracy: 0.9668\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.2085 - accuracy: 0.9332\n",
      "153/153 [==============================] - 2s 16ms/step - loss: 12.8262 - accuracy: 0.0830: 1s - loss: 12.7402 - accuracy: 0.08 - ETA: 1s - loss: 12.7475 - acc - ETA: 0s - loss: 12.5706 - accuracy: 0. - ETA: 0s - loss: 12.5591 - accuracy:\n",
      "\n",
      " Epochs: 40 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.2251 - accuracy: 0.9289\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.1535 - accuracy: 0.9583\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.1399 - accuracy: 0.9577\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.1585 - accuracy: 0.9506\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.1154 - accuracy: 0.9633\n",
      "153/153 [==============================] - 2s 16ms/step - loss: 13.2196 - accuracy: 0.0824: 2s - l - ETA: 0s - loss: 13.0204 - accuracy: 0\n",
      "\n",
      " Epochs: 45 \n",
      "\n",
      "Epoch 1/5\n",
      "155/155 [==============================] - 15s 97ms/step - loss: 0.1105 - accuracy: 0.9654\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.0825 - accuracy: 0.9729\n",
      "Epoch 3/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.0883 - accuracy: 0.9700\n",
      "Epoch 4/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.1303 - accuracy: 0.9605\n",
      "Epoch 5/5\n",
      "155/155 [==============================] - 15s 98ms/step - loss: 0.1453 - accuracy: 0.9530\n",
      "153/153 [==============================] - 2s 16ms/step - loss: 15.2663 - accuracy: 0.0876: 0s - loss: 14.8816 - accurac\n",
      "\n",
      " Epochs: 50 Acc: 0.08756423741579056 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(epochs<50):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_age_M_210_225)\n",
    "        b = \"Epochs: \"+ str(epochs)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_age_M_210_225.save(\"model_MVLP/MVLP_age_M_210_225.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "        print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 1s 7ms/step - loss: 15.2663 - accuracy: 0.0876\n"
     ]
    }
   ],
   "source": [
    "block_age_M_210_225 = tf.keras.models.load_model(\"model_MVLP/MVLP_age_M_210_225.h5\")\n",
    "test_loss, test_acc = block_age_M_210_225.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training age with Female_240_255_270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7230, 86)\n",
      "(7279, 86)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_female:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 240 or p.guessAngle == 255 or p.guessAngle == 270:\n",
    "        x_train.append(p.img)\n",
    "        y_train.append(p.age)\n",
    "        \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = to_cate(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_female:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 240 or p.guessAngle == 255 or p.guessAngle == 270:\n",
    "        x_test.append(p.img)\n",
    "        y_test.append(p.age)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = to_cate(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 86)                88150     \n",
      "=================================================================\n",
      "Total params: 23,334,941\n",
      "Trainable params: 23,334,815\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    block_age_F_240_255_270 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "    block_age_F_240_255_270.add(Dense(86, activation = 'softmax'))\n",
    "    block_age_F_240_255_270.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "    block_age_F_240_255_270.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "226/226 [==============================] - 23s 100ms/step - loss: 11.5074 - accuracy: 0.0442\n",
      "Epoch 2/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 3.7102 - accuracy: 0.0813\n",
      "Epoch 3/5\n",
      "226/226 [==============================] - 23s 101ms/step - loss: 3.4509 - accuracy: 0.1080\n",
      "Epoch 4/5\n",
      "226/226 [==============================] - 23s 100ms/step - loss: 3.3081 - accuracy: 0.1342\n",
      "Epoch 5/5\n",
      "226/226 [==============================] - 22s 100ms/step - loss: 3.2293 - accuracy: 0.1366\n",
      "228/228 [==============================] - 4s 17ms/step - loss: 3.6908 - accuracy: 0.0812\n",
      "\n",
      " Epochs: 5 Acc: 0.08119247108697891 \n",
      "\n",
      "Epoch 1/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 3.0968 - accuracy: 0.1686\n",
      "Epoch 2/5\n",
      "226/226 [==============================] - 23s 100ms/step - loss: 3.0006 - accuracy: 0.1846\n",
      "Epoch 3/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 2.8635 - accuracy: 0.2181\n",
      "Epoch 4/5\n",
      "226/226 [==============================] - 22s 100ms/step - loss: 2.7505 - accuracy: 0.2358\n",
      "Epoch 5/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 2.6078 - accuracy: 0.2671\n",
      "228/228 [==============================] - 4s 17ms/step - loss: 4.2309 - accuracy: 0.0819 2s - loss: 4.1838  - ETA: 1s - l - ETA: 0s - loss: 4.169\n",
      "\n",
      " Epochs: 10 Acc: 0.0818793773651123 \n",
      "\n",
      "Epoch 1/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 2.4429 - accuracy: 0.3019\n",
      "Epoch 2/5\n",
      "226/226 [==============================] - 22s 100ms/step - loss: 2.2808 - accuracy: 0.3577\n",
      "Epoch 3/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 2.0765 - accuracy: 0.3907\n",
      "Epoch 4/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 1.8766 - accuracy: 0.4508\n",
      "Epoch 5/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 1.6243 - accuracy: 0.5159\n",
      "228/228 [==============================] - 4s 17ms/step - loss: 5.6267 - accuracy: 0.0635- ETA: 0s - loss: 5.5619 - \n",
      "\n",
      " Epochs: 15 \n",
      "\n",
      "Epoch 1/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 1.4304 - accuracy: 0.5776\n",
      "Epoch 2/5\n",
      "226/226 [==============================] - 22s 100ms/step - loss: 1.2277 - accuracy: 0.6207\n",
      "Epoch 3/5\n",
      "226/226 [==============================] - 22s 100ms/step - loss: 1.0180 - accuracy: 0.6876\n",
      "Epoch 4/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.8136 - accuracy: 0.7459\n",
      "Epoch 5/5\n",
      "226/226 [==============================] - 23s 100ms/step - loss: 0.6778 - accuracy: 0.7874\n",
      "228/228 [==============================] - 4s 16ms/step - loss: 7.9264 - accuracy: 0.0713\n",
      "\n",
      " Epochs: 20 \n",
      "\n",
      "Epoch 1/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.5892 - accuracy: 0.8097\n",
      "Epoch 2/5\n",
      "226/226 [==============================] - 23s 100ms/step - loss: 0.4859 - accuracy: 0.8479\n",
      "Epoch 3/5\n",
      "226/226 [==============================] - 23s 100ms/step - loss: 0.3721 - accuracy: 0.8822\n",
      "Epoch 4/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.3432 - accuracy: 0.8905\n",
      "Epoch 5/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.2649 - accuracy: 0.9166\n",
      "228/228 [==============================] - 4s 17ms/step - loss: 11.5003 - accuracy: 0.0709\n",
      "\n",
      " Epochs: 25 \n",
      "\n",
      "Epoch 1/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.2682 - accuracy: 0.9172\n",
      "Epoch 2/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.2653 - accuracy: 0.9134\n",
      "Epoch 3/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.2406 - accuracy: 0.9235\n",
      "Epoch 4/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.2129 - accuracy: 0.9339\n",
      "Epoch 5/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.2059 - accuracy: 0.9317\n",
      "228/228 [==============================] - 4s 17ms/step - loss: 14.0748 - accuracy: 0.0602: 3s - loss: 13.7954 - accu - ETA: 2s - loss: 13.6724 - accuracy - ETA: 2s - loss: 13.5506 - - ETA: 1s - loss: 13.7005 - accu - ETA: 0s - loss: 13.8011 - accuracy:\n",
      "\n",
      " Epochs: 30 \n",
      "\n",
      "Epoch 1/5\n",
      "226/226 [==============================] - 22s 100ms/step - loss: 0.2118 - accuracy: 0.9325\n",
      "Epoch 2/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.1779 - accuracy: 0.9477\n",
      "Epoch 3/5\n",
      "226/226 [==============================] - 23s 100ms/step - loss: 0.1414 - accuracy: 0.9584\n",
      "Epoch 4/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.2172 - accuracy: 0.9335\n",
      "Epoch 5/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.1740 - accuracy: 0.9452\n",
      "228/228 [==============================] - 4s 17ms/step - loss: 15.3689 - accuracy: 0.0624: 2s - - ETA: 0s - loss: 15.0819 - accuracy:\n",
      "\n",
      " Epochs: 35 \n",
      "\n",
      "Epoch 1/5\n",
      "226/226 [==============================] - 23s 100ms/step - loss: 0.1859 - accuracy: 0.9434\n",
      "Epoch 2/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.1767 - accuracy: 0.9481\n",
      "Epoch 3/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.1454 - accuracy: 0.9523\n",
      "Epoch 4/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.0953 - accuracy: 0.9710\n",
      "Epoch 5/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.0637 - accuracy: 0.9802\n",
      "228/228 [==============================] - 4s 16ms/step - loss: 15.0324 - accuracy: 0.0611: 0s - loss: 14.7409 - acc\n",
      "\n",
      " Epochs: 40 \n",
      "\n",
      "Epoch 1/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.0934 - accuracy: 0.9711\n",
      "Epoch 2/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.1087 - accuracy: 0.9638\n",
      "Epoch 3/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.0762 - accuracy: 0.9739\n",
      "Epoch 4/5\n",
      "226/226 [==============================] - 23s 100ms/step - loss: 0.0906 - accuracy: 0.9732\n",
      "Epoch 5/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.1060 - accuracy: 0.9686\n",
      "228/228 [==============================] - 4s 16ms/step - loss: 17.9495 - accuracy: 0.0662\n",
      "\n",
      " Epochs: 45 \n",
      "\n",
      "Epoch 1/5\n",
      "226/226 [==============================] - 22s 99ms/step - loss: 0.1412 - accuracy: 0.9573\n",
      "Epoch 2/5\n",
      "226/226 [==============================] - 23s 101ms/step - loss: 0.1705 - accuracy: 0.9555\n",
      "Epoch 3/5\n",
      "226/226 [==============================] - 24s 105ms/step - loss: 0.1257 - accuracy: 0.9629\n",
      "Epoch 4/5\n",
      "226/226 [==============================] - 24s 105ms/step - loss: 0.1111 - accuracy: 0.9665\n",
      "Epoch 5/5\n",
      "226/226 [==============================] - 24s 104ms/step - loss: 0.1155 - accuracy: 0.9683\n",
      "228/228 [==============================] - 4s 17ms/step - loss: 18.2738 - accuracy: 0.0647\n",
      "\n",
      " Epochs: 50 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(epochs<50):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_age_F_240_255_270)\n",
    "        b = \"Epochs: \"+ str(epochs)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_age_F_240_255_270.save(\"model_MVLP/MVLP_age_F_240_255_270.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "        print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 2s 7ms/step - loss: 4.2309 - accuracy: 0.0819\n"
     ]
    }
   ],
   "source": [
    "block_age_F_240_255_270 = tf.keras.models.load_model(\"model_MVLP/MVLP_age_F_240_255_270.h5\")\n",
    "test_loss, test_acc = block_age_F_240_255_270.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training age with Male_240_255_270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7254, 86)\n",
      "(7275, 86)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for p in train_male:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 240 or p.guessAngle == 255 or p.guessAngle == 270:\n",
    "        x_train.append(p.img)\n",
    "        y_train.append(p.age)\n",
    "        \n",
    "x_train = np.array(x_train).reshape(-1, height, width, 1)\n",
    "y_train = to_cate(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for p in test_male:\n",
    "    if p.age == '-':\n",
    "        continue\n",
    "    if p.guessAngle == 240 or p.guessAngle == 255 or p.guessAngle == 270:\n",
    "        x_test.append(p.img)\n",
    "        y_test.append(p.age)\n",
    "    \n",
    "x_test = np.array(x_test).reshape(-1, height, width, 1)\n",
    "y_test = to_cate(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 122, 82, 18)       900       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 61, 41, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 61, 41, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 57, 37, 45)        20295     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 18, 45)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 18, 45)        180       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 22680)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              23225344  \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 86)                88150     \n",
      "=================================================================\n",
      "Total params: 23,334,941\n",
      "Trainable params: 23,334,815\n",
      "Non-trainable params: 126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    block_age_M_240_255_270 = tf.keras.models.load_model('model_MVLP/MVLP_without_output_layer.h5')\n",
    "\n",
    "    block_age_M_240_255_270.add(Dense(86, activation = 'softmax'))\n",
    "    block_age_M_240_255_270.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "    block_age_M_240_255_270.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "227/227 [==============================] - 24s 102ms/step - loss: 12.0036 - accuracy: 0.0421\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 23s 101ms/step - loss: 3.6172 - accuracy: 0.0711\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 23s 101ms/step - loss: 3.4892 - accuracy: 0.0831\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 23s 103ms/step - loss: 3.3682 - accuracy: 0.0987\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 23s 102ms/step - loss: 3.3263 - accuracy: 0.0996\n",
      "228/228 [==============================] - 4s 17ms/step - loss: 3.6099 - accuracy: 0.0841\n",
      "\n",
      " Epochs: 5 Acc: 0.08412370830774307 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 24s 104ms/step - loss: 3.2360 - accuracy: 0.1245\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 25s 108ms/step - loss: 3.1930 - accuracy: 0.1322\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 24s 106ms/step - loss: 3.1499 - accuracy: 0.1431\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 24s 106ms/step - loss: 3.0715 - accuracy: 0.1596\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 23s 102ms/step - loss: 2.9820 - accuracy: 0.1788\n",
      "228/228 [==============================] - 4s 16ms/step - loss: 3.7813 - accuracy: 0.0874 2s - los\n",
      "\n",
      " Epochs: 10 Acc: 0.0874226838350296 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 23s 103ms/step - loss: 2.9455 - accuracy: 0.1864\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 24s 108ms/step - loss: 2.8441 - accuracy: 0.2053\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 24s 107ms/step - loss: 2.7773 - accuracy: 0.2200\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 24s 107ms/step - loss: 2.6675 - accuracy: 0.2479\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 24s 107ms/step - loss: 2.5622 - accuracy: 0.2705\n",
      "228/228 [==============================] - 4s 17ms/step - loss: 4.2861 - accuracy: 0.0873\n",
      "\n",
      " Epochs: 15 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 24s 108ms/step - loss: 2.4913 - accuracy: 0.2938\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 24s 105ms/step - loss: 2.3649 - accuracy: 0.3274\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 23s 102ms/step - loss: 2.2361 - accuracy: 0.3554\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 23s 102ms/step - loss: 2.1100 - accuracy: 0.3907\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 25s 109ms/step - loss: 1.9740 - accuracy: 0.4246\n",
      "228/228 [==============================] - 4s 17ms/step - loss: 4.9235 - accuracy: 0.0803 2s - loss: 4.6655 - ac - ETA: 1s - loss: 4.6838 - accura - ETA: 1s - loss: 4.6704 - accuracy: 0. - ETA: 1s - - ETA: 0s - loss: 4.8545 - accuracy: \n",
      "\n",
      " Epochs: 20 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 23s 101ms/step - loss: 1.8710 - accuracy: 0.4516\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 23s 102ms/step - loss: 1.7130 - accuracy: 0.4870\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 23s 103ms/step - loss: 1.6043 - accuracy: 0.5185\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 23s 103ms/step - loss: 1.4749 - accuracy: 0.5524\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 24s 105ms/step - loss: 1.3430 - accuracy: 0.5907\n",
      "228/228 [==============================] - 4s 16ms/step - loss: 6.4456 - accuracy: 0.0874\n",
      "\n",
      " Epochs: 25 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 24s 104ms/step - loss: 1.2600 - accuracy: 0.6146\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 23s 102ms/step - loss: 1.1355 - accuracy: 0.6518\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 23s 103ms/step - loss: 1.0432 - accuracy: 0.6769\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 23s 102ms/step - loss: 0.9719 - accuracy: 0.6935\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 23s 103ms/step - loss: 0.9184 - accuracy: 0.7146\n",
      "228/228 [==============================] - 4s 17ms/step - loss: 8.6260 - accuracy: 0.0811 1s - loss: 8.1158 - accuracy - E\n",
      "\n",
      " Epochs: 30 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 23s 102ms/step - loss: 0.8141 - accuracy: 0.7451\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 23s 103ms/step - loss: 0.7487 - accuracy: 0.7615\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 24s 105ms/step - loss: 0.6915 - accuracy: 0.7805\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 25s 109ms/step - loss: 0.6769 - accuracy: 0.7892\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 24s 107ms/step - loss: 0.6811 - accuracy: 0.7874\n",
      "228/228 [==============================] - 4s 17ms/step - loss: 10.6216 - accuracy: 0.0669\n",
      "\n",
      " Epochs: 35 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 23s 103ms/step - loss: 0.7204 - accuracy: 0.7793\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 24s 106ms/step - loss: 0.5519 - accuracy: 0.8216\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 29s 130ms/step - loss: 0.5116 - accuracy: 0.8360\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 30s 130ms/step - loss: 0.5059 - accuracy: 0.8437\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 29s 128ms/step - loss: 0.4266 - accuracy: 0.8650\n",
      "228/228 [==============================] - 5s 20ms/step - loss: 12.2585 - accuracy: 0.0740: 0s - loss: 11.7946 - acc\n",
      "\n",
      " Epochs: 40 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 29s 129ms/step - loss: 0.4115 - accuracy: 0.8674\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 29s 126ms/step - loss: 0.4096 - accuracy: 0.8677\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 26s 115ms/step - loss: 0.4530 - accuracy: 0.8565\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 26s 115ms/step - loss: 0.3676 - accuracy: 0.8843\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 26s 114ms/step - loss: 0.3653 - accuracy: 0.8861\n",
      "228/228 [==============================] - 4s 18ms/step - loss: 13.1211 - accuracy: 0.0785\n",
      "\n",
      " Epochs: 45 \n",
      "\n",
      "Epoch 1/5\n",
      "227/227 [==============================] - 26s 114ms/step - loss: 0.3785 - accuracy: 0.8785\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 26s 115ms/step - loss: 0.3543 - accuracy: 0.8896\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 26s 115ms/step - loss: 0.3098 - accuracy: 0.9003\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 26s 114ms/step - loss: 0.3012 - accuracy: 0.9068\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 27s 120ms/step - loss: 0.3044 - accuracy: 0.9035\n",
      "228/228 [==============================] - 5s 21ms/step - loss: 15.4340 - accuracy: 0.0757A: 0s - loss: 15.1373 - accuracy: 0.\n",
      "\n",
      " Epochs: 50 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "epochs = 0\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    while(epochs<50):\n",
    "        epochs += 5\n",
    "        new_acc = train(block_age_M_240_255_270)\n",
    "        b = \"Epochs: \"+ str(epochs)\n",
    "        if new_acc > acc:\n",
    "            acc = new_acc\n",
    "            block_age_M_240_255_270.save(\"model_MVLP/MVLP_age_M_240_255_270.h5\")\n",
    "            b = \"Epochs: \"+ str(epochs) + \" Acc: \" + str(acc)\n",
    "        print (\"\\n\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 2s 8ms/step - loss: 3.7813 - accuracy: 0.0874\n"
     ]
    }
   ],
   "source": [
    "block_age_M_240_255_270 = tf.keras.models.load_model(\"model_MVLP/MVLP_age_M_240_255_270.h5\")\n",
    "test_loss, test_acc = block_age_M_240_255_270.evaluate(x_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
